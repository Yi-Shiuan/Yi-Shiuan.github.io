{"pageProps":{"current":2,"posts":[{"id":1639958400,"fileName":"dotnetconf-2021@study4","url":"2021/12/20/dotnetconf-2021@study4","title":"從黑暗時代到現代化的雲端部署與維運","description":"dotnetconf 2021 ＠ study4 從黑暗時代到現代化的雲端部署與維運","tags":["azure","vmss","cd","devops","prevision","study4","dotnetconf"],"date":"2021-12-20T00:00:00.000Z","published":true,"content":"\ndotnetconf 2021 ＠ study4 從黑暗時代到現代化的雲端部署與維運\n\n[投影片下載](https://cdn.adhome.com.tw/blogger/dotnetconf2021@STUDY4.pdf)\n\n## IAC 說明\n\n[IaC Repo](https://github.com/Yi-Shiuan/dotnet-conf-iac)\n\n### website 資料夾\n\nwebsite資料夾是建立各個環境的資源檔案，內容記載該服務需要產生哪些的資源項目以及各個環境上的配置，裡面的部分採用terraform撰寫\n\n- `main.tf` => 用來設定資院建立的內容與設定\n- `variable.tf` => 定義整個腳本中有哪些變數\n- `vars 資料夾` => 每一個環境上的設定值\n\n### initial-script\n\n自動安裝腳本，這裡面的`main.sh`是整個警本的進入點，每一個服務都會有一個資料夾，資料夾內會有一個`install.sh`的檔案，這是實際上application真正執行部署的腳本\n由main.sh去下載install.sh，並且執行install.sh\n\n\n"},{"id":1635552000,"fileName":"logstash-azure-event-hub-input","url":"2021/10/30/logstash-azure-event-hub-input","title":"Logstash Azure event hub input 設定","description":"最近又在規劃ELK的設定，這次比較不一樣的地方我選擇了elastic cloud以及服務部署的方式都採用PaaS的方式作為部署， 加掛volume或是在機器上安裝filebeat都是一個比較困難的事情，所以一開始考慮使用azure blob queue的方式存放log， 但後來選擇了官方有提供的input套件，Azure Event Hub來寫log在使用logstash去讀取傳送到elasticsearch上","date":"2021-10-30T00:00:00.000Z","tags":["azure","elk"],"published":true,"content":"\n最近又在規劃ELK的設定，這次比較不一樣的地方我選擇了elastic cloud以及服務部署的方式都採用PaaS的方式作為部署，\n加掛volume或是在機器上安裝filebeat都是一個比較困難的事情，所以一開始考慮使用azure blob queue的方式存放log，\n但後來選擇了官方有提供的input套件，Azure Event Hub來寫log在使用logstash去讀取傳送到elasticsearch上\n\n根據官網的文件操作後會一直出現\n`The configuration will result in overwriting offsets. Please ensure that the each Event Hub's consumer_group is using a unique storage container.`\n這樣的錯誤訊息，也採用了進階的設定去使用，但因為只有一組採用進階的方式設定有點太過複雜所以又改回原本設定，後來想我的event hub的connection string有兩組會不會因為這樣我需要多個storage container的存放空間，\n後來將其中一組刪除後即可正常運作\n\n```config\n# 會出錯的logstash pipeline config\ninput {\n    azure_event_hubs {\n        event_hub_connections => [\"Endpoint=sb://<<event hub>>.servicebus.windows.net/;SharedAccessKeyName=logsta...\",\n            \"Endpoint=sb://<<event hub>>.servicebus.windows.net/;SharedAccessKeyName=logsta...\"]\n        storage_connection => \"DefaultEndpointsProtocol=https;...\"\n        consumer_group => \"logstash\"\n        decorate_events => true\n        threads => 8\n    }\n}\nfilter {\n    json {\n        source => \"message\"\n    }\n    date {\n        match => [ \"Timestamp\", \"ISO8601\" ]\n        target => \"@timestamp\"\n    }\n    mutate {\n        rename => [\"MessageTemplate\", \"message\" ]\n        rename => [\"Level\", \"level\" ]\n        merge => { \"message\" => \"Exception\" }\n        remove_field => [\"Exception\", \"Timestamp\"]\n    }\n}\noutput {\n    elasticsearch {\n        cloud_id => \"<<Cloud id>>\"\n        cloud_auth => \"<<user>>:<<password>>\"\n        index => \"demo-%{+YYYY.w}\"\n    }\n}\n```\n\n```config\n# 最後的 logstash pipeline config\ninput {\n    azure_event_hubs {\n        event_hub_connections => [\"Endpoint=sb://<<event hub>>.servicebus.windows.net/;SharedAccessKeyName=logsta...\"]\n        storage_connection => \"DefaultEndpointsProtocol=https;...\"\n        consumer_group => \"logstash\"\n        decorate_events => true\n        threads => 8\n    }\n}\nfilter {\n    json {\n        source => \"message\"\n    }\n    date {\n        match => [ \"Timestamp\", \"ISO8601\" ]\n        target => \"@timestamp\"\n    }\n    mutate {\n        rename => [\"MessageTemplate\", \"message\" ]\n        rename => [\"Level\", \"level\" ]\n        merge => { \"message\" => \"Exception\" }\n        remove_field => [\"Exception\", \"Timestamp\"]\n    }\n}\noutput {\n    elasticsearch {\n        cloud_id => \"<<Cloud id>>\"\n        cloud_auth => \"<<user>>:<<password>>\"\n        index => \"demo-%{+YYYY.w}\"\n    }\n}\n```\n\n\n### 參考資料\n[Github - logstash-input-azure_event_hubs](https://github.com/logstash-plugins/logstash-input-azure_event_hubs)\n"},{"id":1628812800,"fileName":"azure-managed-certificate-app-service","url":"2021/08/13/azure-managed-certificate-app-service","title":"受Azure管理的免費憑證","description":"在網頁開發中，SSL憑證已經是一個不可或缺的一件事情！網路上可以找到許多免費的憑證使用，如let's encrypt、ZeroSSL 都可以幫你產生免費的憑證，唯一麻煩的事情是三個月就需要重新處理憑證問題，在雲端供應商中AWS有提供ACM微軟也有提供類似於ACM的服務， 只要你使用了這些雲端供應商就可以免費的為你產生憑證","date":"2021-08-13T00:00:00.000Z","tags":["devops","azure","ssl"],"published":true,"content":"\n在網頁開發中，SSL憑證已經是一個不可或缺的一件事情！網路上可以找到許多免費的憑證使用，如[let's encrypt](https://letsencrypt.org/zh-tw/)、\n[ZeroSSL](https://zerossl.com/)都可以幫你產生免費的憑證，唯一麻煩的事情是三個月就需要重新處理憑證問題，當然熟悉腳本處理的可以透過一些自動化的方式來處理只是需要花點時間撰寫這些腳本\n在雲端供應商中AWS有提供ACM微軟也有提供類似於ACM的服務，只要你使用了這些雲端供應商就可以免費的為你產生憑證\n\n## 設定方式\n\nAzure 坦白說UI真的不是很直覺，這也是微軟一直以來的硬傷，這個設定其實藏在我們一直看得到的地方但又不會去點他的一個按鈕\n\n再進入設定之前，必須要將自訂的domain綁在Azure app service上（或Azure functions）才能夠產生憑證，點下`Create App Service Managed Certificate`\n後只需要點選你要的Domain 就可以產生了，整個過程約3-5分鐘左右，如果有多個子網域都需要SSL的話就多點幾次\n\n![Azure 受管的 SSL](azure-managed-certificate-app-service/azure-managed-ssl.png)\n\n![Azure 產生 SSL](azure-managed-certificate-app-service/create-ssl.png)\n\n產生SSL憑證後需要到`TSL/SSL Setting`中，將剛才建立的SSL綁定到相對應的Domain name上就可以了\n\n![Azure 綁定 SSL](azure-managed-certificate-app-service/azure-ssl-binding.png)\n\n## 使用條件與限制\n\n憑證一定位有到期日期，在微軟提供的憑證中有效期間是6個月，在六個月到期後會自動的幫你renew這個憑證直到你刪除app service或azure functions等服務，\n必須要可以自訂domain name的規格才能夠產生免費的憑證(B1等級以上)\n\n> 此免費憑證有下列限制：\n>\n>  - 不支援萬用字元憑證。\n>  - 不支援以憑證指紋作為用戶端憑證的使用方式， (移除憑證指紋的) 計畫。\n>  - 不可匯出。\n>  - App Service 環境 (ASE) 上並不支援。\n>  - 與流量管理員整合的根域不支援。\n>  - 如果是 CNAME 對應網域的憑證，則 CNAME 必須直接對應至 {app-name}.azurewebsites.net 。\n>\n> [在 Azure App Service 中新增 TLS/SSL 憑證](https://docs.microsoft.com/zh-tw/azure/app-service/configure-ssl-certificate)\n"},{"id":1617753600,"fileName":"selenium-grid-4","url":"2021/04/07/selenium-grid-4","title":"Selenium Grid 4 體驗","description":"最近在處理系統交接並且升級相關的系統發現了Selenium Grid出了第四版現正Beta時讓我躍躍欲試， 以前Selenium Grid 3.x版本的時候UI說真的不怎麼樣，做了Selenium Grid 4的時候樣式跟整個畫面的設計全改了。 整個畫面看起來舒服了不少，但相關的東西也改了不少讓我一開始做測試的時候跌了不少次","date":"2021-04-07T00:00:00.000Z","tags":["selenium"],"published":true,"content":"\n最近在處理系統交接並且升級相關的系統發現了Selenium Grid出了第四版現正Beta時讓我躍躍欲試，\n以前Selenium Grid 3.x版本的時候UI說真的不怎麼樣，做了Selenium Grid 4的時候樣式跟整個畫面的設計全改了。\n整個畫面看起來舒服了不少，但相關的東西也改了不少讓我一開始做測試的時候跌了不少次\n\n![selenium 4](selenium-grid-4/selenium-4.png)\n\n## Selenium 架構變更\n\n在[Selenium Component](https://www.selenium.dev/documentation/en/grid/grid_4/components_of_a_grid/)文件中就給了一張架構圖，\n跟過去只有HUB跟Node的架構有所差距，在整個部署與調整上擁有了更多彈性。你可以將HUB分散在多台的Server做部署，\n或是你可以使用經典模式的HUB將這些分散的服務集中在HUB中。\n\n新增的component有以下幾個，或者是你可以使用Hub來取代這些新的component\n- Router\n- Distributor\n- Session Map\n- New Session Queuer\n- Event Bus\n\n## Selenium Node Session的改變\n\n在以前Selenium 3.x的時候，我們可以去使用MAX_SESSIONS指定該instance的Session數量，所以在自動化測試的機器叢集中我都直接給10個讓每一個node都具有10個session，\n但這一次改版後即便你加了`SE_NODE_MAX_SESSIONS`的數量，但你的CPU數量不足時也無法產生更多的Session，新版本Node的Session數量取決於你設定的最大Session與CPU最小的那一個\n在官方的github中[這一段說明](https://github.com/SeleniumHQ/docker-selenium#increasing-session-concurrency-per-container)沒仔細看還真的很容易就給他忽略過去\n\n## Dynamic Grid的使用\n\n在新版本的Selenium Grid支援了Dynamic Grid，可以在每一次測試的時候才產生相對應的目標瀏覽器，而不用預先建置好這些瀏覽器的session\n\n在公司的Selenium的測試從集中，都採用docker的方式啟動這個對我來說可以減少在infrastructure的設定與管理\n\n以下分享我的設定，在config.toml的部分讓docker-node可以使用host的docker花了一下功夫\n\n```coffeescript\n# config.toml\n\n[docker]\n# Configs have a mapping between the Docker image to use and the capabilities that need to be matched to\n# start a container with the given image.\nconfigs = [\n    \"selenium/standalone-firefox:4.0.0-beta-3-prerelease-20210402\", \"{\\\"browserName\\\": \\\"firefox\\\"}\",\n    \"selenium/standalone-chrome:4.0.0-beta-3-prerelease-20210402\", \"{\\\"browserName\\\": \\\"chrome\\\"}\",\n    \"selenium/standalone-opera:4.0.0-beta-3-prerelease-20210402\", \"{\\\"browserName\\\": \\\"operablink\\\"}\",\n    \"selenium/standalone-edge:4.0.0-beta-3-prerelease-20210402\", \"{\\\"browserName\\\": \\\"msedge\\\"}\"\n    ]\n\n# URL for connecting to the docker daemon\n# host.docker.internal works for macOS and Windows.\n# Linux could use --net=host in the `docker run` instruction or 172.17.0.1 in the URI below.\n# To have Docker listening through tcp on macOS, install socat and run the following command\n# socat -4 TCP-LISTEN:2375,fork UNIX-CONNECT:/var/run/docker.sock\nurl = \"unix:///var/run/docker.sock\"\n# Docker imagee used for video recording\nvideo-image = \"selenium/video:ffmpeg-4.3.1-20210402\"\n\n# Uncomment the following section if you are running the node on a separate VM\n# Fill out the placeholders with appropriate values\n#[server]\n#host = <ip-from-node-machine>\n#port = <port-from-node-machine>\n\n[selenium official github](https://github.com/SeleniumHQ/docker-selenium#dynamic-grid-)\n```\n\n```yml\nversion: \"3\"\nservices:\n  node-docker:\n    image: selenium/node-docker:4.0.0-beta-3-prerelease-20210402\n    user: root\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - ./config.toml:/opt/bin/config.toml\n    depends_on:\n      - hub\n    environment:\n      - SE_EVENT_BUS_HOST=hub\n      - SE_EVENT_BUS_PUBLISH_PORT=4442\n      - SE_EVENT_BUS_SUBSCRIBE_PORT=4443\n      - SE_NODE_OVERRIDE_MAX_SESSIONS=true\n      - SE_NODE_MAX_SESSIONS=10\n  hub:\n    image: selenium/hub:4.0.0-beta-3-prerelease-20210402\n    user: root\n    ports:\n      - \"4442:4442\"\n      - \"4443:4443\"\n      - \"4444:4444\"\n    logging:\n      options:\n        max-size: 100m\n        max-file: \"1\"\n    restart: always\n```\n\n## 參考連結\n\n[Selenium document](https://www.selenium.dev/documentation/en/grid/grid_4/components_of_a_grid/)\n\n[Max sessions](https://github.com/SeleniumHQ/docker-selenium#increasing-session-concurrency-per-container)\n"},{"id":1617235200,"fileName":"select-number-tdd","url":"2021/04/01/select-number-tdd","title":"Select Number TDD練習","description":"之前同事去參加面試，在面試的時候有一道上機考的題目，我覺得很有趣並且是一個很好練習的一道題目，一開始我讓我們前端的新人試著寫出這道題， 沒想到所有新人都完成了，所以我想嘗試一下TDD的方式來撰寫這道題目。","date":"2021-04-01T00:00:00.000Z","tags":["tdd","react","jest"],"published":true,"content":"\n之前同事去參加面試，在面試的時候有一道上機考的題目，我覺得很有趣並且是一個很好練習的一道題目，一開始我讓我們前端的新人試著寫出這道題，\n沒想到所有新人都完成了，所以我想嘗試一下TDD的方式來撰寫這道題目。\n\n## 練習題目需求\n\n1. 每一區有1~10個數字，點擊後會變成選取狀態，再次點擊後取消選取\n1. 在畫面上共有4個區域，每個區域都有10個數字，每區選取的號碼不能重複選取(ex: 第一區選擇\"1\"則其他區數字\"1\"為不可選)\n1. 每一區都有一個重置按鈕，點擊後該區選取的數字要被清空，並且所有區可以選取胎數字\n\n## 事後檢討\n\n一開始我的commit是有循序漸進的但後面亂掉了，變成了一個commit有多個事件處理。\n第二個是在重構的時候沒有及時的重構，所以在後面開始出現了很多個重構的commit。\n\n[repo](https://github.com/Yi-Shiuan/select-numbers)\n"},{"id":1610409600,"fileName":"the-react-first-time","url":"2021/01/12/the-react-first-time","title":"React 入門的學習之路","description":"昨天面試一位React新手雖然最後因為一些原因沒有Hire她，但他問了一個問題讓我覺得很棒：可以有什麼方法可以讓我的能力加強嗎？ 在我第一次接觸React距今已經過了好久了，久到我已經忘記我是如何啟動第一個React的APP...但身為一個React開發者又是一位面試官的角色， 未來還會有更多學習React的新手不斷進入，我想好好分享一下在面試一個React的新人時我在乎哪些技能另外也能當作學習React的入門時一個學習路徑","date":"2021-01-12T00:00:00.000Z","tags":["react"],"published":true,"content":"\n昨天面試一位React新手雖然最後因為一些原因沒有Hire她，但他問了一個問題讓我覺得很棒：`可以有什麼方法可以讓我的能力加強嗎？`\n\n在我第一次接觸React距今已經過了好久了，久到我已經忘記我是如何啟動第一個React的APP...但身為一個React開發者又是一位面試官的角色，\n未來還會有更多學習React的新手不斷進入，我想好好分享一下在面試一個React的新人時我在乎哪些技能另外也能當作學習React的入門時一個學習路徑\n\n## Local state的應用\n\n在學習React的第一步，當然建議可以先從`npx create-react-app my-app`開始，當然第一步就是在畫面印出簡單的文字來當作一個進入點，\n在這之後建議可以開始做一個簡單的ToDo List的小專案，來體驗整個React的語法、JSX與Component等等的設計，Function Component與Class Component\n都要體驗一下。\n\n## Global state的使用\n\n在學會了React的local state的應用也做了一個簡單的todo list之後，我建議學習一下Redux或是其他Global state的套件來改寫一下剛才的todo list\n嘗試幾筆新增資料後，在畫面上驅動更新顯示出來\n\n在Global state我建議的是使用Redux與React Hook的Context兩種全域的狀態管理都要學習，畢竟未來進入職場的時候不知道會使用哪一個\n\n## Virtual DOM\n\n在學習Global state之後，當然建議好好惡補一下Virtual DOM這個東西，這對未來的職涯上有很大的幫助，但又偏偏許多人忽略這個東西的養成...\n\n## Fetch API\n\n當Global state上手後，建議練習一下在React的APP中呼叫一下api取得資料與送出資料的練習，畢竟在工作上有很大的概率出現的\n在呼叫API的部分我建議做兩個的練習，一個是使用fetch的方式另一個是axios的套件，然後了解一下這兩個的使用限制與優缺\n\n## Component 的設計\n\n在Global state後，嘗試一下把todo list的Component拆分成多個Component來練習，深入了解一下state與props的相異之處使用條件與限制，\n也把Global state的狀態應用在Component中，嘗試一下使用props與Global state來更新todo list的資料，然後觀察一下其中的差異與變化。\n\n## 生命週期\n\n最後我的建議是React的生命週期，觸發render的時機等等的這些生命週期，這會讓你在React的道路上可以少踩一些地雷或是少遇到一些錯誤。\n\n\n以上是我在近期面試許多React的新手與昨天面試的同學提問後，參與自身的學習經驗來給未來新入React的朋友簡單的一個路徑。\n當然學習路徑有很多但我面試時偏好也會問這類的問題，從中鑑別候選人對React的理解程度。\n\n###\n[建立全新的 React 應用程式](https://zh-hant.reactjs.org/docs/create-a-new-react-app.html)\n"},{"id":1610064000,"fileName":"elasticsearch-tuning-and-auto-operation","url":"2021/01/08/elasticsearch-tuning-and-auto-operation","title":"Elasticsearch 效能調整與自動維運","description":"在Index Management中有個index templates的頁簽，在這裡可以改變一些index的行為或是屬性， 有些index屬性對於整個ELK的查詢或是機器的影響是很巨大的，當Log量越大的時候就需要改變一些設定， 尤其是放在雲端的ELK，如果使用越大的機器消費金額就會變得很可觀，在不是賺錢的機器上還是能省則省。","date":"2021-01-08T00:00:00.000Z","tags":["elk","devops"],"published":true,"content":"\n## 針對index的一些效能調校\n\n在Index Management中有個index templates的頁簽，在這裡可以改變一些index的行為或是屬性，\n有些index屬性對於整個ELK的查詢或是機器的影響是很巨大的，當Log量越大的時候就需要改變一些設定，\n尤其是放在雲端的ELK，如果使用越大的機器消費金額就會變得很可觀，在不是賺錢的機器上還是能省則省。\n\n`index.codec`在官方的文件中有兩個選項，預設是Default採用LZ4的壓縮，另一個選項是*best_compression*，\n使用它可以得到更高的壓縮效率但會增加CPU的附載，不過減少硬碟的空間是可觀的\n\n`refresh_interval`這個在官方文件說明是index的刷新頻率，這個選項會影響到新增的log多久內可能不會被看見，\n但refresh index他需要消耗許多的CPU來處理，這個值如果越大刷新的頻率就會降低，機器的CPU usage就不會被這個吃掉，\n可以減少一些CPU的運算\n\n`number_of_replicas`是Elasticsearch會建立多少個副本，但複本越多所需要消耗的CPU與硬碟空間就會加大\n\n```json\n{\n  \"index\": {\n    \"lifecycle\": {\n      \"name\": \"production\"\n    },\n    \"codec\": \"best_compression\",\n    \"refresh_interval\": \"15s\",\n    \"number_of_replicas\": 0\n  }\n}\n```\n\n## 自動維運Index的小技巧\n\n通常架設了ELK初期會常常觀看一些硬碟空間, CPU usage, Memory usage等等的，時間久了就會忘記了...\n\n但是硬碟的空間是有限的，Application Log其實也是有時效性的，他不需要永久的存在在硬碟上(畢竟要花錢的...)所以自動刪除index就變得很重要，\n在Index Lifecycle Policies中我會設定兩個policy，一個production跟一個non-production的，production通常會留存30天以，\n而非production的一般來說在兩週到三週就沒有參考價值了，所以非production只留存14天。\n\n![ELK index lifecycle](elasticsearch-tuning-and-auto-operation/index-lifecycle.png)\n\n## 參考連結\n[Elasticsearch Index Module](https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html)\n\n[Tune for indexing speed](https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html)\n"},{"id":1609977600,"fileName":"best-practice-layout-in-nextjs","url":"2021/01/07/best-practice-layout-in-nextjs","title":"Next.js 的Layout最佳配置","description":"新專案即將完成之際，我們開始對各個頁面上的效能與一些過去被我們忽略的問題進行修正， 在這修正的過程中我發現了在每一次頁面切換時都會出現網站的Logo消失又再出現的問題， Logo是一個經常變動的圖片所以在專案中是透過GQL取得Logo的CDN位置後才做渲染的， 再深入排查後才發現原來過去我的觀念不是非常正確所以用這篇來筆記一下正確地處理做法，當作小抄避免未來再犯同樣的錯誤。","date":"2021-01-07T00:00:00.000Z","tags":["react","next.js","frontend","layout"],"published":true,"content":"\n## 前情提要\n\n新專案即將完成之際，我們開始對各個頁面上的效能與一些過去被我們忽略的問題進行修正，\n在這修正的過程中我發現了在每一次頁面切換時都會出現網站的Logo消失又再出現的問題，\nLogo是一個經常變動的圖片所以在專案中是透過GQL取得Logo的CDN位置後才做渲染的，\n再深入排查後才發現原來過去我的觀念不是非常正確所以用這篇來筆記一下正確地處理做法，當作小抄避免未來再犯同樣的錯誤。\n\n## Next.js Layout最佳配置\n\n在Next.js的Layout最佳配置應該是把Layout的component放在`_app.tsx`中，在轉換頁面時就不會再出現前情提要的相關問題了。\n\n```typescript jsx\nfunction App({Component, pageProps }: AppProps): any {\n\tconst apolloClient: any = useApollo(pageProps.initialApolloState);\n\n\treturn <ApolloProvider client={apolloClient}>\n\t\t    <Layout>\n\t\t\t    <Component {...pageProps} />\n\t\t\t</Layout>\n\t\t</ApolloProvider>\n}\n```\n\n```typescript jsx\nconst Index: NextPage<any> = (props: any): any => {\n\treturn <>\n            {/*index content*/}\n\t\t</>\n};\n```\n\n\n### 在得到結論前的一些排查點\n\n在一開始我們的`_app.tsx`與`index.tsx`或其他page都是這樣的設計，在Layout中有`Header`與`Footer`兩個component以及負責所有頁面上的版面配置，\n其中Header這個component中去取得GQL資料，但因為他是屬於React FunctionComponent的範疇，故無法使用getInitialProps這類的function\n\n```typescript jsx\nfunction App({Component, pageProps }: AppProps): any {\n\tconst apolloClient: any = useApollo(pageProps.initialApolloState);\n\n\treturn <ApolloProvider client={apolloClient}>\n\t\t\t<Component {...pageProps} />\n\t\t</ApolloProvider>\n}\n```\n\n```typescript jsx\nconst Index: NextPage<any> = (props: any): any => {\n\treturn <Layout>\n            {/*index content*/}\n\t\t</Layout>\n};\n```\n\n1. 在方案一的我是透過React Memo的方式Cache Layout起來下次使用Layout 這個component時就不會再重新渲染，但結果是仍然每次重新渲染Layout\n1. 在_app.tsx中取得相關的Layout配置所需要的圖檔與文字，透過props的方式傳入給Layout中並讓Header在Server side 渲染，\n但因為progress image的使用所以Logo仍然會有閃一下的情況\n\n然後在官網上看到了這麼一段....\n最後我把Layout放置到`_app.tsx`中，就可以如我們預期的一開始出現了progress image的Logo再出現真正的Logo，在每次轉頁時也沒有重新渲染相關的Layout component\n\n我想主要的幾個原因是，_app.tsx的執行時間以及在轉頁渲染的最小單位是整個Next page不是採用差異的方式重新渲染。\n\n> Next.js uses the App component to initialize pages. You can override it and control the page initialization. Which allows you to do amazing things like:\n>\n> - Persisting layout between page changes\n> - Keeping state when navigating pages\n> - Custom error handling using componentDidCatch\n> - Inject additional data into pages\n> - Add global CSS\n>\n> [Next.js Custom APP](https://nextjs.org/docs/advanced-features/custom-app)\n\n### 相關連結\n\n[Next.js Custom APP](https://nextjs.org/docs/advanced-features/custom-app)\n"},{"id":1607472000,"fileName":"ec2-provisioned-self-install","url":"2020/12/09/ec2-provisioned-self-install","title":"如何讓AWS EC2開機後就能上線","description":"在雲端服務一定會遇到的是機器的擴展(scale out)與縮編(scale in)的問題，如果一個AutoScaling Group觸發了機器的成長時肯定是無法靠手動 的方式來安裝機器，所以必須要透過全資動畫的方式進行，這時候我一開始的想法是在AutoScaling發生的時候觸法Jenkins的Job來安裝系統， 但這有個問題是我整個aws的服務都必須依賴在Jenkins上，後來同事指導了一個做法只需要透過AWS的設定就可以自動裝機了！","tags":["ec2","aws","cd","devops","prevision"],"date":"2020-12-09T00:00:00.000Z","published":true,"content":"\n## 寫在前面\n\n在雲端服務一定會遇到的是機器的擴展(scale out)與縮編(scale in)的問題，如果一個AutoScaling Group觸發了機器的成長時肯定是無法靠手動\n的方式來安裝機器，所以必須要透過全資動畫的方式進行，這時候我一開始的想法是在AutoScaling發生的時候觸法Jenkins的Job來安裝系統，\n但這有個問題是我整個aws的服務都必須依賴在Jenkins上，後來同事指導了一個做法只需要透過AWS的設定就可以自動裝機了！\n\n## User Data\n\n一直以來都沒從還沒注意過AWS在建立EC2或是在Launch template介面上的`user data`，user data中的指令AWS會在我們EC2開機的過程中為我們執行\n如此一來就可以不需要依賴任何一個工具就可以完成茲動畫的作業了。\n\n![create instance 的 user data](ec2-provisioned-self-install/ec2-create-instance.png)\n\n![launch template 的 user data](ec2-provisioned-self-install/launch-template.png)\n\n```sh\n#!/bin/bash -xe\naws s3 cp s3://{{your s3 bucket}}/main.sh main.sh --region {{your region}}\nbash main.sh\n```\n\n> 在我同事的指點中，他建議在user data中不要放置帶多的指令碼而是用來下載入口指令碼與執行入口指令碼的內容就好\n\n### main.sh\n\n在入口腳本中一個很重要的事情是辨識機器需要安裝哪些東西以及要做哪些事情，但不太想讓user data有太多的版本避免團隊成員中複製時出錯，\n所以在EC2的Tag中做了一些手腳，依照EC2 Tag的設定安裝不同的軟體\n\n在取得EC2 Tag時其實需要先做很多事情，首先要先取得EC2 instance Id...但取的EC2 Instance Id前要先取得Region....\n然後發現有個的API endpoint，這API endpoint 主要是取得主機的相關資料，然侯回傳的是一個Json的資料格式\n\n在shell 操作Json的資料格式，不外乎就是jq這個套件了...所以我的入口腳本第一件事就是安裝jq，接下來才是去取得EC2 instance的資料\n\n當有了instance id與region時就可以取得Tag資訊了\n\n> EC2的Tag\n> 1. Service: 設定機器主要承載的服務類型\n> 2. Docker: 是否為這台機器安裝docker\n\n```sh\n#!/bin/bash -xe\n\nexec > >(tee /var/log/user-data.log|logger -t user-data -s 2>/dev/console) 2>&1\nsudo yum install -y jq\nsudo apt-get install -y jq\n\nREGION=`curl -s http://169.254.169.254/latest/dynamic/instance-identity/document | jq .region -r`\naws s3 cp s3://ec2-initial-script/functions.sh ./functions.sh --region ap-northeast-1\nsource ./functions.sh\nlog \"Start setup script\"\n\nlog \"EC2 Instance Process\" \"Region:\" $REGION\nEC2_INSTANCE_ID=`curl -s http://169.254.169.254/latest/dynamic/instance-identity/document | jq .instanceId -r`\nlog \"EC2 instance Id: ${EC2_INSTANCE_ID}\"\nTAGS=\"$(aws ec2 describe-tags --filter \"Name=resource-id,Values=${EC2_INSTANCE_ID}\" --region ${REGION})\"\n\nlog \"DOCKER Process\"\nDOCKER=`echo $TAGS | jq -r '.Tag[] | select(.Key == \"Docker\").Value'`\nlog \"DOCKER Install ${DOCKER}\"\n\nif [[ \"$DOCKER\" == \"yes\" ]]; then\n    log \"DOCKER Install ... \"\n    sudo yum update -y\n    sudo amazon-linux-extras install docker -y\n    sudo service docker start\n    sudo usermod -a -G docker ec2-user\n    sudo systemctl restart docker\n    log \"DOCKER Install Successfully\"\n\n    log \"DOCKER-COMPOSE Install ... \"\n    sudo curl -L \"https://github.com/docker/compose/releases/download/1.25.0/docker-compose-$(uname -s)-$(uname -m)\" \\\n              -o /usr/local/bin/docker-compose\n    sudo chmod +x /usr/local/bin/docker-compose\n    sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose\n    sudo systemctl enable docker\n    log \"DOCKER-COMPOSE Install Successfully \"\nfi;\n\nSERVICE=`echo $TAGS | jq -r '.Tag[] | select(.Key == \"Service\").Value'`\nlog \"Download ${SERVICE}.sh\"\naws s3 cp s3://{{s3 bucket}}/$SERVICE/install.sh /install.sh\n\nlog \"Execute ${SERVICE} script\"\nbash install.sh \"${TAGS}\" \"${REGION}\" \"${EC2_INSTANCE_ID}\"\n\nlog \"End scripting\"\n```\n### install.sh\n\nuser data只負責下載與執行入口腳本在入口腳本中還要執行服務腳本，服務腳本是用來安裝application的！\n在入口腳本中會用EC2的Service Tag到S3 Bucket下載對應的install.sh來安裝與設定application所需要的設定\n\n#### ECS的安裝腳本\n\n```sh\n#!/bin/bash -xe\n\nsource ./functions.sh\nTAGS=$1\nREGION=$2\nINSTANCE=$3\n\nlog \"ECS Install ... \"\n\nECS_CLUSTER=`echo $TAGS | jq -r '.Tag[] | select(.Key == \"ECS:cluster\").Value'`\nsudo mkdir /etc/ecs\ncat << EOF > /etc/ecs/ecs.config\nECS_DATADIR=/data\nECS_ENABLE_TASK_IAM_ROLE=true\nECS_ENABLE_TASK_IAM_ROLE_NETWORK_HOST=true\nECS_LOGFILE=/log/ecs-agent.log\nECS_AVAILABLE_LOGGING_DRIVERS=[\"json-file\",\"awslogs\"]\nECS_LOGLEVEL=info\nECS_CLUSTER=$ECS_CLUSTER\nEOF\n\ndocker run -d --name ecs-agent \\\n    --detach=true \\\n    --restart=always \\\n    --volume=/var/run:/var/run \\\n    --volume=/var/log/ecs/:/log \\\n    --volume=/var/lib/ecs/data:/data \\\n    --volume=/etc/ecs:/etc/ecs \\\n    --net=host \\\n    --env-file=/etc/ecs/ecs.config \\\n    --log-driver json-file \\\n    --log-opt max-size=100m \\\n    amazon/amazon-ecs-agent:latest\n\nlog \"ECS Install Successfully \"\n```\n\n### 總結\n\n使用user data可以做到系統自動化而且還不需要依賴任何的工具，不過在使用這樣的方式時需要對整個OS, shell script（如果用windows就得對powershell熟悉）\n以及對aws cli有足夠的能力才有機會做出這樣的腳本，有了這樣的腳本才能做到100％的自動化。\n在目前已經做到完整的自動化的部署模式，我們團隊的CI server, Staging環境每天下班後自動關機上班前會自動開機並且安裝整個application\n在production的環境裡，自動化擴展時Windows的機器約莫15分鐘，Linux的機器約莫5~7分鐘就能設定完成並且服務\n\n> 在AWS的Image中只設定了預先裝好IIS的Windows機器，此目的是為了節省安裝IIS的時間成本讓機器可以更快的上線服務減少支出\n> 其他Linux的機器都只有選擇AWS Linux2的image，並沒有特別做任何設定\n>\n> windows的機器在AWS開機使用T3.Medium的速度一般來說都在15分鐘左右完成\n\n### EC2 instance 的相關時間估算\n\n| Target         | Script  | 請求機器    | 移交機器    | Provisioned | Health check | 上線時間      |\n|----------------|---------|---------|---------|-------------|--------------|-----------|\n| Windows Server | 3~5 min | 1.5 min | 7~9 min | 5 min       | 1.5min       | 15~22 min |\n| Linux Server   | 3~5 min | 1.5 min | 5~7 min | 3 min       | 1.5min       | 9~13 min  |\n\n## 相關連結\n\n[JQ github page](https://stedolan.github.io/jq/)\n"},{"id":1600473600,"fileName":"terraform-aws-infrastructure-as-code","url":"2020/09/19/terraform-aws-infrastructure-as-code","title":"Terraform 做 AWS IaC","description":"一直在公司使用ansible來做Cloud configuration但是ansible在cloud configuration上說真的略顯不足， 在之前的文章中我們很常使用`aws cli`來做相對應的處理。使用aws cli時要有更好的可讀性與維護性，通常都以JSON的格式輸入 因此在ansible中的playbook上就會有多餘的一些步驟去設定餵給aws cli的JSON。","tags":["aws","iac","terraform"],"date":"2020-09-19T00:00:00.000Z","published":true,"content":"\n## 寫在前面\n\n一直在公司使用ansible來做Cloud configuration但是ansible在cloud configuration上說真的略顯不足，\n在之前的文章中我們很常使用`aws cli`來做相對應的處理。使用aws cli時要有更好的可讀性與維護性，通常都以JSON的格式輸入\n因此在ansible中的playbook上就會有多餘的一些步驟去設定餵給aws cli的JSON。\n\n這一篇就用terraform來建立一個aws AutoScaling Group吧！\n\n## 安裝Terraform\n\nterraform的安裝其實非常簡單，在下方的參考連結中有其他的安裝方式，我這邊主要會使用mac的安裝方式\n\n在mac安裝terraform我是透過[Homebrew](https://brew.sh/index_zh-tw)來安裝terraform\n\n```shell script\n# For mac\nbrew install hashicorp/tap/terraform\n```\n\n安裝完成後做一個簡單的驗證，開啟你習慣的terminal執行以下的command就可以知道我們是不是有安裝成功了，\n如果安裝成功就會出現跟下圖一樣的資訊出來，就可以進行下一步了！\n\n\n```shell script\nterraform -help\n```\n\n![安裝terrafrom的驗證](terraform-aws-infrastructure-as-code/terraform-install.png)\n\n> 如果透過Homebrew安裝不成功，可以試試看brew upgrade，更新一下homebrew\n\n因terraform最後會產生aws cli的command，在安裝完畢後需要安裝aws cli並且設定aws的一些infomation\n並且設定aws的access key跟secert key的部分\n\n```shell script\n# install aws cli\nbrew install awscli\n\n# configure aws setting\naws configure\n```\n\n## 初始化terraform\n\n這一篇的目標是要用terrafrom建立aws 的auto scaling group，\b在達成目標前terraform前需要先做初始化\n\n初始化其實非常容易，先在你的terraform的資料夾下先建立一個`main.tf`的黨案，定義provider\n\n執行`init`後會有下方的資訊出現並且在資料夾中會有一個`.terraform`的資料夾\n\n```hlc\nterraform {\n  required_version = \">= 0.13\"\n}\n\nprovider \"aws\"\n  region = \"ap-northeast-1\"\n}\n```\n\n\n```shell script\nterraform init\n```\n\n![terraform init訊息](terraform-aws-infrastructure-as-code/terraform-init.png)\n\n## 透過terrafrom 建立 AWS AutoScaling Group\n\n接下來要建立一個`main.tf`或是使用前一步的`main.tf`，撰寫resource的設定有關於aws 的resource定義資料\n可以參考下方的參考連結中的**terraform aws provider**\n\n```hlc\nresource \"aws_autoscaling_group\" \"asg\" {\n  name                      = \"test-autoscaling-group\"\n  max_size                  = 1\n  min_size                  = 1\n  health_check_grace_period = 300\n  health_check_type         = \"ELB\"\n  desired_capacity          = 1\n  force_delete              = true\n  availability_zones        = [\"ap-northeast-1a\", \"ap-northeast-1d\"]\n  launch_template {\n    id      = \"lt-xxxxxxxx\" # 使用前需要把Id置換掉\n    version = \"$Latest\"\n  }\n}\n```\n\n### Apply\n在terraform要真的去建立資源的command 是`apply`，在真正到aws上建立資源前會有一個預覽資料等待你的確認才會真正的建立資源\n\n```shell script\nterraform apply\n```\n\n> 如果在CI的魔是可以透過auto-approve，來略過確認輸入的情況\n\n### Plan\n\n如果你想先看看資源變更的情況或是dry run時可以使用`plan`來先做預覽\n預覽後可以直接變更資源如下方圖片中的的文字 **terraform apply \"plan\"**\n\n```shell script\nterraform plan -out plan\n\n#確認後可以執行\nterraform apply \"plan\"\n```\n\n![terraform plan](terraform-aws-infrastructure-as-code/terraform-plan.png)\n\n## Oops！我的Resource被修改了！\n\n在完成第一個resource的建立後，要建立第二個autoscaling時我用了這樣的main.tf，但是出現了一些狀況...\n\n```hlc\nresource \"aws_autoscaling_group\" \"asg\" {\n  name                      = \"test-autoscaling-group2\"\n  max_size                  = 1\n  min_size                  = 1\n  health_check_grace_period = 300\n  health_check_type         = \"ELB\"\n  desired_capacity          = 1\n  force_delete              = true\n  availability_zones        = [\"ap-northeast-1a\", \"ap-northeast-1d\"]\n  launch_template {\n    id      = \"lt-xxxxxxxx\" # 使用前需要把Id置換掉\n    version = \"$Latest\"\n  }\n}\n```\n\n這時候發現剛才建立的resource被刪除並重新建立了，\n這個原因是因為你當下的資料夾出現了terraform.tfstate的檔案，將你剛才的資源資訊存放在此以便後續的資源管理\n但...我該如何產生其他新的auto scaling group呢？\n\n答案是使用terraform workspace的方式去建立一個新的workspace，讓每一個資源都是互相獨立的\n\n```shell script\nterraform workspace new auto-scaling-group-2\n```\n\n![terraform workspace](terraform-aws-infrastructure-as-code/terraform-workspace.png)\n\n接下來再重新執行一次plan指令就會發現預覽的資訊上變成了新建而不是刪除重建的狀態\n\n## Terraform的文件管理分享\n\n隨著管理的資源的建立開始會發現有許多重複的main.tf，然後要修改某個資訊要修改多個main.tf，那要如何去共用這些main.tf呢？\n\n在結構分享前我先介紹幾個terraform重要的檔案，詳細的設定請看參考連結中的`terraform configuration language`官網介紹\n\n- main.tf\n\n    main.tf是要設定AWS或是其他雲端的資源設定\n\n- variables.tf\n\n    variables.tf 則是預先定義變數，在main.tf中所用的變數資料都要在此先做定義\n\n- xxxxx.tfvars\n\n    `.tfvars` 則是預先輸入好的參數設定，後續就不需要在cli中輸入大量的資訊\n\n\n![terraform 的資料夾結構](terraform-aws-infrastructure-as-code/terraform-folder.png)\n\n在資料夾結構中，我依照aws的服務去建立相關的資料夾（如：alb, auto scaling group等等）去建立資料夾\n在每個資料夾下都會有main.tf, variables.tf, xxxxx.tfvars的檔案，在workspace的命名上會採用與tfvars的檔名相同\n並且會把workspace的名稱打在aws 服務的tag中方便未來做管理。\n\n> Tips: 在variables.tf中的變數宣告建議都放上預設值，未來要刪除資源時會更加方便！\n\n\n## 參考連結\n\n[Install Terraform](https://learn.hashicorp.com/tutorials/terraform/install-cli#install-terraform)\n\n[terraform aws provider](https://registry.terraform.io/providers/hashicorp/aws/latest/docs)\n\n[terraform configuration language](https://www.terraform.io/docs/configuration/index.html)\n"}],"allTags":{"react":5,"next.js":3,"i18n":1,"gatsby.js":1,"postgresql":1,"database":2,"dotnet":1,"aws":4,"devops":7,"prevision":6,"iot":2,"platformio":2,"arduino":2,"esp":1,"elk":3,"azure":4,"vulnerability":1,"ssl":2,"vmss":1,"cd":3,"study4":1,"dotnetconf":1,"selenium":2,"tdd":1,"jest":1,"frontend":1,"layout":1,"ec2":1,"iac":1,"terraform":1,"ci":1,"jenkins":1,"ecs":1,"ansible":1,"redis":2,"protobuf":2,"serialize":2,"deserialize":2,"pub":1,"sub":1,"notify":1},"total":26},"__N_SSG":true}