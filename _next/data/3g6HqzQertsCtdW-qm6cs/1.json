{"pageProps":{"current":1,"posts":[{"id":1666224000,"fileName":"gatsbyjs-to-nextjs","url":"2022/10/20/gatsbyjs-to-nextjs","title":"從Gatsby.js轉換到Next.js","description":"紀錄從Gatsby.js轉換到了Next.js的踩地雷過程","date":"2022-10-20T00:00:00.000Z","tags":["gatsby.js","next.js"],"published":true,"content":"\n其實Gatsby.js並沒有什麼不好，只是他每一次改版都需要花費許多精力去做更新，我從1.0用到了3.0，最後4.0真的讓我痛下決心轉換到了Next.js的懷抱\n\n雖然官方有介紹如何從Gatsby.js遷移到Next.js的範例，但說真的還有許多沒有寫清楚的地方這邊先做幾個紀錄\n\n## 更新package.json\n\n除離移除所有的Gatsby.js的套件外，還需要安裝幾個套件這幾個套件官方都有說明主要是為了渲染markdown的文件以及讀取markdown的文件的套件功能\n\n```json\n{\n  \"scripts\": {\n    \"build\": \"next build\",\n    \"export\": \"next export\",\n    \"dev\": \"next dev\",\n    \"start\": \"next start\"\n  },\n  \"subpath\": \"`/*\",\n  \"dependencies\": {\n    \"gray-matter\": \"^4.0.3\",\n    \"next\": \"^12.3.1\",\n    \"react-markdown\": \"^8.0.3\",\n    \"react-syntax-highlighter\": \"^15.4.4\",\n    \"remark\": \"^14.0.2\",\n    \"remark-html\": \"^15.0.1\"\n  }\n}\n```\n\n## 讀取markdown檔案\n\n在部落格中的markdown文件資料夾是這樣放的 `src/posts/{post}.mdx`\n\n```typescript\n// posts.ts\n\nimport dayjs from 'dayjs';\nimport fs from 'fs';\nimport matter from 'gray-matter';\nimport { join } from 'path';\n\nexport type Post = {\n    id: number;\n    fileName: string;\n    url: string;\n    title: string;\n    tags: string[];\n    content: string;\n    date: Date;\n    publish: boolean;\n    description: string;\n}\n\nconst postsDirectory = join(process.cwd(), '<<markdown 檔案位置>>');\nlet posts: Post[] = [];\n\n// 取得markdown文件中的內容\nexport const getPost: Function = (slug: string): Post => {\n    const realSlug = slug.replace(/\\.mdx$/, '');\n    const fullPath = join(postsDirectory, `${ slug }`);\n    const fileContents = fs.readFileSync(fullPath, 'utf8');\n    const {\n        data,\n        content,\n    } = matter(fileContents);\n\n    const obj = JSON.parse(JSON.stringify(data));\n    return {\n        id: dayjs(data.date).unix(),\n        fileName: realSlug,\n        url: `${ dayjs(data.date).format('YYYY/MM/DD') }/${ realSlug }`,\n        ...obj,\n        content,\n    } as Post;\n};\n\n// 列表目標資料夾中的所有markdown檔案，並且逐一取得markdown文件中的資料\nexport const getAllPosts: Function = (): Post[] => {\n    if ( posts.length === 0 ) {\n        const slugs = fs.readdirSync(postsDirectory);\n        posts = slugs.map((slug) => {\n            return getPost(slug);\n        });\n    }\n\n    return posts;\n};\n```\n\n## 文章列表\n\n有了這些，就可以把文章列表的部分印出來了！\n\n```typescript jsx\nexport const getStaticProps: GetStaticProps = async (context: GetStaticPropsContext<ParsedUrlQuery>): Promise<any> => {\n    const posts: Post[] = getAllPosts();\n    return {\n        props: {\n            posts: posts.slice(0, 10)\n        },\n    };\n};\n```\n\n## 文章內文\n\n接下來要讀取markdown中的內容，並且渲染出整個html，然後我也有針對markdwon的element做客制處理，例如`h1`的渲染就會如同下方的html\n\n```typescript jsx\nexport const h1 = (props: any) => {\n    const {children} = props;\n\n    return <div className={classNames(\"u-heading-v3\", \"g-mb-40\")}>\n        <h1 className={classNames(\"h1\", \"u-heading-v3__title\")}>\n            {children}\n        </h1>\n    </div>\n}\n```\n\n另外官方給的方式，渲染移植會有錯誤（如下圖），所以自己做了一個呈現的頁面，讓畫面可以有更完整的客製化功能\n\n![渲染錯誤](gatsbyjs-to-nextjs/render-error.png)\n\n```typescript jsx\nimport { NextPage } from 'next';\nimport ReactMarkdown from 'react-markdown';\n\nconst Posts: NextPage = (props: any) => {\n    return <>\n        <div className={ classNames('g-mb-30') }>\n             {/*略*/}\n            <ReactMarkdown components={ connponents }>{ props.content }</ReactMarkdown>\n        </div>\n        {/*略*/}\n    </>;\n};\n\nexport const getStaticProps: GetStaticProps = async ({ params }: any): Promise<any>  => {\n    const post = getPost(`${params.post[3]}.mdx`);\n    return {\n        props: {\n            ...post\n        },\n    };\n};\n\nexport const getStaticPaths: GetStaticPaths = async (): Promise<any>  => {\n    const posts = getAllPosts();\n    return {\n        paths: posts.map((post: Post) => {\n            return {\n                params: {\n                    post: post.url.split('/').map(i => i.toString()),\n                },\n            };\n        }),\n        fallback: false,\n    };\n};\n```\n\n## Tag標籤\n\n在Gatsby.js可以透過gql把文章標籤弄出來但在next.js中就只能自己處理了..\n\n我先在posts.ts中新加一個method，可以處理把文章的tag都列出來，然後在每一頁中添加印出tag的處理，這樣子就把原本Gatsby原有的功能做出來了！接下來差了分頁功能...\n\n```typescript\n// posts.ts\nexport const getTags: Function = (): { [index: string]: number } => {\n    const tags: { [index: string]: number } = {};\n    posts.forEach((post: Post) => {\n        post.tags.forEach((tag: string) => {\n            if ( tags[tag] === undefined ) {\n                tags[tag] = 1;\n            } else {\n                tags[tag]++;\n            }\n        });\n    });\n\n    return tags;\n};\n\n// pages/*\nexport const getStaticProps: GetStaticProps = async ({ params }: any): Promise<any>  => {\n    // 略\n    const allTags = getTags();\n    return {\n        props: {\n            // 略\n            allTags\n        },\n    };\n};\n```\n\n## 關於分頁功能\n\n每一頁只顯示10篇文章，所以在`index.tsx`先hard code 只取得文章前10筆，接下來再運用`getStaticPaths`的方式就可以達成分頁功能了！\n\n```typescript jsx\nindex.tsx中的getStaticProps\nexport const getStaticProps: GetStaticProps = async (context: GetStaticPropsContext<ParsedUrlQuery>): Promise<any> => {\n    const posts: Post[] = getAllPosts();\n    const allTags = getTags();\n    return {\n        props: {\n            posts: posts.slice(0, 10),\n            allTags,\n            total: posts.length\n        },\n    };\n};\n\n// [page].tsx\nexport const getStaticProps: GetStaticProps = async (context: GetStaticPropsContext<ParsedUrlQuery>): Promise<any> => {\n    const {\n        page,\n    }: any = context.params;\n\n    const posts: Post[] = getAllPosts();\n    const allTags = getTags();\n\n    const current = parseInt(page ?? '0');\n\n    return {\n        props: {\n            current,\n            posts: posts.slice((current - 1) * 10, current * 10),\n            allTags,\n            total: posts.length,\n        },\n    };\n};\n\nexport const getStaticPaths: GetStaticPaths = async (): Promise<any> => {\n    const pages = [];\n    const posts: Post[] = getAllPosts();\n\n    for (let i = 0; i < posts.length / 10; i++) {\n        pages.push({\n                       params: {\n                           page: `${ i + 1 }`,\n                       },\n                   });\n    }\n\n    return {\n        paths: pages,\n        fallback: false,\n    };\n};\n```\n\n## 參考連結\n\n[Next.js Migrate from Gatsby.js](https://nextjs.org/docs/migrating/from-gatsby)\n"},{"id":1664841600,"fileName":"postgresql-insert-or-update","url":"2022/10/04/postgresql-insert-or-update","title":"Postgresql 的Merge語法","description":"在SQL Server中有一個語法是merge的語法，他可以根據特定的條件執行特定的操作，如資料存在就更新不存在就新增。 但在Postgresql中，似乎沒有merge的語法可以使用...但在程式理先去得資料在判斷是否更新或新增這樣的情境容易導致一些後遺症.... 在google後，其實有很多方式但...嘗試後只有這個方法是可行的，所以在這邊筆記一下","date":"2022-10-04T00:00:00.000Z","tags":["postgresql","database"],"published":true,"content":"\n在SQL Server中有一個語法是`merge`的語法，他可以根據特定的條件執行特定的操作，如資料存在就更新不存在就新增。\n但在Postgresql中，似乎沒有merge的語法可以使用...但在程式理先去得資料在判斷是否更新或新增這樣的情境容易導致一些後遺症....\n在google後，其實有很多方式但...嘗試後只有這個方法是可行的，所以在這邊筆記一下\n\n> postgresql的版本是13\n\n```plsql\nINSERT INTO public.table (user_id, name, email)\nVALUES (@userid, @username, @user_email)\nON CONFLICT (user_id)\n    DO UPDATE SET (name, email) = (@username, @user_email)\nWHERE members.user_id = @userid;\n```\n當table中user_id衝突時，就會自動執行update，這樣一來根SQL server中的merge語句就相同了！\n\n\n### 參考資料\n\n[postgresql insert](https://www.postgresql.org/docs/current/sql-insert.html)\n"},{"id":1664496000,"fileName":"postgresql-dapper-json-deserialize","url":"2022/09/30/postgresql-dapper-json-deserialize","title":"透過Dapper存取Postgresql Json column 自動反序列化","description":"有時候一個物件我會把它序列化後使用JSON的方式存放到postgresql中，但把它取出後卻無法透過ORM直接做資料的對應，然後自己就土炮了做法， 把資料撈出後在針對欄位去反序列化，這樣做一開始覺得好像沒什麼，但這樣的資料變多了以後發現問體頗大，所以上網找了一些解決方案， 但關鍵字嚇得不好反而找到許多更奇怪的做法後來在stackoverflow上看到了這招真心覺得很棒的方法，於是筆記下來！","tags":["database","dotnet"],"date":"2022-09-30T00:00:00.000Z","published":true,"content":"\n有時候一個物件我會把它序列化後使用JSON的方式存放到postgresql中，但把它取出後卻無法透過ORM直接做資料的對應，然後自己就土炮了做法，\n把資料撈出後在針對欄位去反序列化，這樣做一開始覺得好像沒什麼，但這樣的資料變多了以後發現問體頗大，所以上網找了一些解決方案，\n但關鍵字嚇得不好反而找到許多更奇怪的做法後來在stackoverflow上看到了這招真心覺得很棒的方法，於是筆記下來！\n\n當初也有嘗試過使用`CustomPropertyTypeMap`來處理，但這個對於欄位與Class屬性名稱對應不同時使用，\n當欄位資料需要做特殊的轉換時就需要Dapper的ITypeHandler來定義什麼樣的資料型別需要怎麼去做處理，\n所以建立了一個class去繼承 `SqlMapper.ITypeHandler`然後實作類似Get/Set的物件存取的方式。\n\n```cs\npublic class JsonTypeHandler : SqlMapper.ITypeHandler\n{\n    public void SetValue(IDbDataParameter parameter, object value)\n    {\n        parameter.Value = JsonSerializer.Serialize(value);\n    }\n\n    public object Parse(Type destinationType, object value)\n    {\n        return value == null ? destinationType : JsonSerializer.Deserialize(value.ToString()!, destinationType);\n    }\n}\n```\n\n做好了這樣的物件後，只要在資料庫的連線物件上註冊`當遇到xxxx`型別時，使用JsonTypeHandler做處理，這樣一來就必須要土炮把資料撈出來後\n使用callback的方式做反序列化在僵值放回原本需要的物件中，減少了許多複雜的狀態。\n\n```cs\npublic class DbContext\n{\n    private string connectionString;\n    private readonly ILogger<DbContext> logger;\n\n    public DbContext(IServiceProvider provider)\n    {\n        略...\n\n        // 先決定目標的型別，再來把相對應的處理方式填上就行了\n        SqlMapper.AddTypeHandler(typeof(Dictionary<string, string>), new JsonTypeHandler());\n    }\n\n    /// 略...\n}\n```\n\n## 參考資料\n\n[can-dapper-deserialize-json-stored-as-text](https://stackoverflow.com/questions/49888334/can-dapper-deserialize-json-stored-as-text)\n"},{"id":1658793600,"fileName":"from-dark-age-to-mondern-deployment","url":"2022/07/26/from-dark-age-to-mondern-deployment","title":"從黑暗時代到現代化的雲端部署與維運 July 26 @ DevOps","description":"從黑暗時代到現代化的雲端部署與維運 July 26 @ DevOps","tags":["aws","devops","prevision"],"date":"2022-07-26T00:00:00.000Z","published":true,"content":"\n從黑暗時代到現代化的雲端部署與維運 July 26 @ DevOps\n\n[投影片下載](https://cdn.adhome.com.tw/blogger/從黑暗時代到現代化的雲端部署與維運July-26@DevOps.pdf)\n\n### 影片\n\n[YouTube 直播回放](https://www.youtube.com/watch?v=M0Am63ehgvE&ab_channel=DevOpsTaiwan)\n\n### 參考資料\n\n[如何讓AWS EC2開機後就能上線](https://brunojan.net/posts/2020/12/09/ec2-provisioned-self-install)\n"},{"id":1654732800,"fileName":"nodemcu-esp8266-platformio-with-clion","url":"2022/06/09/nodemcu-esp8266-platformio-with-clion","title":"使用Clion搭配platformio開發esp8266","description":"最近想把家中的電器可以跟apple homekit結合在一起省去一些麻煩順便可以帶來生活更好的狀態，但apple homekit的冷氣控制一個就要3700原， 對於家中有六台冷氣的我有點小貴，所以決定自己開發這樣的產品...順便也改造一下不太好用的窗簾機器人，讓他可以直接支援apple homekit，不需要再透過`捷徑`的方式來支援homekit\n在開始之前研究了一下許多arduino與Raspberry Pi兩者之間的選擇，發現了arduino在整個生態系來說完整不少，缺點是他基本上只支援C/C++的開發... Raspberry Pi 倒是可以使用.net或是node.js等等的語言，但許多的控制器或是傳感器支援的數量較少，並且價格也比較昂貴所以最後選擇了arduino， arduino中也有許多不同的板子，在選擇的時候的非常的困擾...後來我選擇了由樂鑫開發的ESP系列的板子好處是他已經內建了wifi功能， 所以可以直接使用不需要再加上wifi模組！","date":"2022-06-09T00:00:00.000Z","tags":["iot","platformio","arduino","esp"],"published":true,"content":"\n最近想把家中的電器可以跟apple homekit結合在一起省去一些麻煩順便可以帶來生活更好的狀態，但apple homekit的冷氣控制一個就要3700原，\n對於家中有六台冷氣的我有點小貴，所以決定自己開發這樣的產品...順便也改造一下不太好用的窗簾機器人，讓他可以直接支援apple homekit，不需要再透過`捷徑`的方式來支援homekit\n\n在開始之前研究了一下許多arduino與Raspberry Pi兩者之間的選擇，發現了arduino在整個生態系來說完整不少，缺點是他基本上只支援C/C++的開發...\nRaspberry Pi 倒是可以使用.net或是node.js等等的語言，但許多的控制器或是傳感器支援的數量較少，並且價格也比較昂貴所以最後選擇了arduino，\narduino中也有許多不同的板子，在選擇的時候的非常的困擾...後來我選擇了由樂鑫開發的ESP系列的板子好處是他已經內建了wifi功能，\n所以可以直接使用不需要再加上wifi模組！\n\n### CLion Plugin設定\n\nJetBrains開發工具真的都不錯所以我開發iot時我也選用了JetBrains的工具，在研究的時候也有人使用vs code跟arduino IDE來開發，CLion的安裝過程就不在這邊說了\n\nCLion在開發arduino必要安裝的套件有兩個，一個是`Arduino Support`另一個是`PlatformIO for CLion`這兩個就是圖片中第一個與第五個plugin，其他的你可以選用來安裝。\n\n![已安裝的CLion Plugins](nodemcu-esp8266-platformio-with-clion/plugins.png)\n\n### PlatformIO cli 安裝\n\n系統安裝需要有python3，在mac中已經有內建的python3，所以透過pip安裝platformio就可以或是透過Homebrew安裝也可以\n\n```shell\n# PIP install\npip3 install platformio\n# Homebrew 安裝\nbrew install platformio\n```\n> 透過python安裝時，一定要使用python 3.8以上的版本，不然會失敗\n\n### 新增專案\n\nESP8266是NodeMCU ESP-12E的版本，所以這邊選擇NodeMCU下的ESP-12E的專案類型\n\n![CLion 新增專案](https://cdn.adhome.com.tw/blogger/nodemcu-esp8266-platformio-with-clion/new-project.png)\n\n建立完成後就會看到下面這張圖片的狀態一樣，接下來只要把程式碼寫到`src/main.cpp`就可以上傳到ESP8266的板子上了！\n\n![CLion 專案初始](https://cdn.adhome.com.tw/blogger/nodemcu-esp8266-platformio-with-clion/project-init-folder.png)\n"},{"id":1654041600,"fileName":"arduino-use-platformio-upload-error","url":"2022/06/01/arduino-use-platformio-upload-error","title":"使用platformio上傳arduino時出現錯誤代碼(0107)","description":"第一次接觸arduino，很開心地寫下了一個閃爍板子上的LED程式碼後要上傳到板子，結果上傳時發生了錯誤 出現了Failed to write to target RAM (result was 0107)這樣的錯誤代碼，試了網路上很多的方式都沒有成功，最後發現了原來serial port 不正確...","date":"2022-06-01T00:00:00.000Z","tags":["iot","platformio","arduino"],"published":true,"content":"\n第一次接觸arduino，很開心地寫下了一個閃爍板子上的LED程式碼後要上傳到板子，結果上傳時發生了錯誤\n出現了Failed to write to target RAM (result was 0107)這樣的錯誤代碼，試了網路上很多的方式都沒有成功，最後發現了原來serial port\n不正確...\n\n以下是上傳時發生的錯誤訊息資料\n```text\n/usr/local/bin/platformio -c clion run --target upload -e nodemcuv2\nProcessing nodemcuv2 (platform: espressif8266; board: nodemcuv2; framework: arduino)\n\nVerbose mode can be enabled via `-v, --verbose` option\nCONFIGURATION: https://docs.platformio.org/page/boards/espressif8266/nodemcuv2.html\nPLATFORM: Espressif 8266 (3.2.0) > NodeMCU 1.0 (ESP-12E Module)\nHARDWARE: ESP8266 80MHz, 80KB RAM, 4MB Flash\nPACKAGES:\n - framework-arduinoespressif8266 @ 3.30002.0 (3.0.2)\n - tool-esptool @ 1.413.0 (4.13)\n - tool-esptoolpy @ 1.30000.201119 (3.0.0)\n - tool-mklittlefs @ 1.203.210628 (2.3)\n - tool-mkspiffs @ 1.200.0 (2.0)\n - toolchain-xtensa @ 2.100300.210717 (10.3.0)\nLDF: Library Dependency Finder -> https://bit.ly/configure-pio-ldf\nLDF Modes: Finder ~ chain, Compatibility ~ soft\nFound 35 compatible libraries\nScanning dependencies...\nNo dependencies\nBuilding in release mode\nRetrieving maximum program size .pio/build/nodemcuv2/firmware.elf\nChecking size .pio/build/nodemcuv2/firmware.elf\nAdvanced Memory Usage is available via \"PlatformIO Home > Project Inspect\"\nRAM:   [===       ]  34.2% (used 28032 bytes from 81920 bytes)\nFlash: [===       ]  25.4% (used 265729 bytes from 1044464 bytes)\nConfiguring upload protocol...\nAVAILABLE: espota, esptool\nCURRENT: upload_protocol = esptool\nLooking for upload port...\nAuto-detected: /dev/cu.usbmodem53770161961\nUploading .pio/build/nodemcuv2/firmware.bin\nesptool.py v3.0\nSerial port /dev/cu.usbmodem53770161961\nConnecting....\nChip is ESP8266EX\nFeatures: WiFi\nCrystal is 26MHz\nMAC: e8:db:84:df:34:f7\nUploading stub...\n\nA fatal error occurred: Failed to write to target RAM (result was 0107)\n*** [upload] Error 2\n [FAILED] Took 2.01 seconds\n\nProcess finished with exit code 1\n```\n\n### 確認線材\n\n因為板子上的usb介面事mirco usb的介面，這個介面很多的線材是只有充電功能而已無法做資料傳輸，所以...首先要先確定你的線材是不是可以做資料傳輸的用途，\n否則做了再多的工作可能都無法上傳成功\n\n因此我還上了pchome購買了usb type-c to mirco usb的資料傳輸線...\n\n### 驅動程式\n\n我使用的板子是nodeMCU ESP-12E(ESP-8266的板子，晶片是CH9102X)，搭配的事CLion的IDE開發工具\n\n在網路上找到的問題主要都是第一次上傳到板子沒有安裝相對應的驅動程式所以導致錯誤發生，如果發生這個狀態好解決，安裝相對應的驅動程式就可以解決了\nESP8266的晶片有兩種一種是CH9102另一種是CP2102，網路上搜尋的時候還會出現CH340相關的資料，CH340跟CH9102是相同的所以安裝的時候可以找到CH34x的驅動安裝後即可\n但...如果還是不行，可以先確定一下電腦是否有抓到板子在做下一步\n\n```shell\npio device list\n```\n以下是我的output資訊，有看到`/dev/cu.xxxxxx`的資料，就表示真的有抓到板子囉！但如果看到了這樣的輸出，還是出現了\n`A fatal error occurred: Failed to write to target RAM (result was 0107)`的錯誤，該怎麼辦？\n\n```shell\n/dev/cu.BLTH\n------------\nHardware ID: n/a\nDescription: n/a\n\n/dev/cu.Bluetooth-Incoming-Port\n-------------------------------\nHardware ID: n/a\nDescription: n/a\n\n/dev/cu.wchusbserial53770161961\n-------------------------------\nHardware ID: USB VID:PID=1A86:55D4 SER=5377016196 LOCATION=20-2\nDescription: USB Single Serial\n\n/dev/cu.usbmodem53770161961\n---------------------------\nHardware ID: USB VID:PID=1A86:55D4 SER=5377016196 LOCATION=20-2\nDescription: USB Single Serial\n```\n\n### 確認upload port的設定\n\n安裝驅動跟確認線材的問題我卡了許久，也確認了許多次數後我發現我的輸出錯誤都是在使用`/dev/cu.usbmodem53770161961`這個serial port上傳，\n然後偶爾會出現資院忙碌中的錯誤\n```shell\ncould not open port '/dev/cu.usbmodem53770161961': [Errno 16] could not open port /dev/cu.usbmodem53770161961: [Errno 16] Resource busy:.....\n```\n\n在查詢資料過程中想起了一個設定，那就是指定上傳的serial port想說隨便試試看是不是因為serial port的問題...畢竟每次都卡在同一個port上乾脆換一個試試看\n所以我在platfromio.ini這個檔案上增加了一行upload_port的設定，沒想到就出現成功的資訊了！如果你在pio device list看到兩個port這個方法可以試試看，或許有用\n\n```text\n[env:nodemcuv2]\nplatform = espressif8266\nboard = nodemcuv2\nframework = arduino\nupload_port = /dev/cu.wchusbserial53770161961\n```\n"},{"id":1653004800,"fileName":"self-hosted-elasticsearch-8.2","url":"2022/05/20/self-hosted-elasticsearch-8.2","title":"自建Elasticsearch 8.2","description":"這週在處理自建的elasticsearch相關的狀況，今天處理告一段落後來個小筆記未來遇到才不會又搞了老半天...","date":"2022-05-20T00:00:00.000Z","tags":["elk","prevision"],"published":true,"content":"\n這週在處理在azure自建的elasticsearch相關的狀況，今天處理告一段落後來個小筆記未來遇到才不會又搞了老半天...\n\n為什麼要自建elastic呢？主要因為之前使用azure marketplace建立的elastic cloud的saas服務，現在需要把維運的職責交給SRE團隊，\n在移交的過程中發現了azure marketplace所建立的saas服務竟然不能移轉owner！只能將該服務的權限做共享而且必須將訂閱升級到Golden的等級，\n代表每個月的azure帳單又要多最少百元美金的支出...未來帳號如果被停用或是變更，有可能elastic cloud上的資料會有所影響，迫於無奈下只好走向自建的路了\n\n在自建時需要選好許多azure的服務相關的infra設計這些工作可少不了...最後決定了這些infra與azure的服務\n\n#### 1. elasticsearch server + kibana server\n\n使用vmss的服務建立虛擬機器，虛擬機器的規格是使用E2s v5的規格，根據過往經驗elasticsearch伺服器在尖峰的狀態下會使用較多的記憶體，而對於cpu要求較少一些\n對於網路的頻寬要求與對於硬碟的iops都有較大的要求，所以選用了esv5等級的機器\n\n#### 2. logstash server\n\nlogstash 服務也是採用vmss來建立虛擬機器，比較不一樣的是logstash對於cpu的要求較多，他需要去解析log還要針對log做相對應的處理，所以我們選用的是B1s的規格\n然後針對他cpu與memory的使用率做scale out/in的處理\n\n在主機中我使用的是container而非直接安裝相關的服務，然後搭配過去preversion的手法來建立伺服器。\n\n#### 3. Storage\n\n存放資料的磁區選用，這個在規劃時的poc最為困擾...在azure直接使用virtual machine的服務可以掛載managed disk的磁區，但使用vmss產生的vm是無法使用managed disk的！\n但...vmss或是vm建立的硬碟會隨這vm刪除或關閉而消失，所以我們必須得用另外一組的硬碟...後來找到了另外一種解決方案，azure file的服務，\n這樣一來就可以透過SMB掛載一個永久的硬碟，未來的log就能完整地被保留下來不會因為vm被刪除而消彌。\n\n> ps. azure file目前還不知道這樣的使用情境可以支撐多少的iops寫入與讀取，有待未來實驗\n> 根據官方文件指出每秒的iops是20,000 IOPS的讀取的速度基本上可以跟SSD差不多\n\n### 內建帳號使用 Service account token\n\n在使用8.0過後的版本kibana的服務官方預設不使用帳號密碼的方式登入，需要使用service account token的方式登入連線，然後按照官方的指引點入的連結會請你呼叫建立token的api\n```sh\n# create service account token\ncurl -X POST -u elastic:changeme \"localhost:9200/_security/service/elastic/fleet-server/credential/token?pretty\"\n```\nresponse\n```json\n{\n  \"created\": true,\n  \"token\": {\n    \"name\": \"token1\",\n    \"value\": \"AAEAAWVsYXN0aWM...vZmxlZXQtc2VydmVyL3Rva2VuMTo3TFdaSDZ\"\n  }\n}\n```\n然後在kibana上使用service account token登入，但只使用這樣的方式建立的token放在kibana上使用是可以登入elasticsearch，\n但在操作indices的時候就會出現錯誤`security_exception`說你沒有權限取得indices的資料\n```yaml\n# kibana.yml config\nserver.name: kibana\nserver.host: 0.0.0.0\nelasticsearch.hosts: [ \"http://{{elasticsearch}}:{{port}}\" ]\nxpack.monitoring.ui.container.elasticsearch.enabled: true\n\nelasticsearch.serviceAccountToken: AAEAAWVs......EtHd1E\n```\n好的，後來發現其實api呼叫的參數不對，官方在錯誤輸出的console上給的網址是會呼叫fleet-server的服務，而不是給kibana使用的所以我們要把fleet-server的token\n改成kibana服務的token，這樣就可以登入並且取得indices的資料順利的啟動kibana了\n```shell\n# for create kibana service account\ncurl -X POST -u elastic:changeme \"localhost:9200/_security/service/elastic/kibana/credential/token?pretty\"\n```\n```shell\n# check permission\ncurl -H \"Authorization: Bearer AAE.......1E\" -X GET \"localhost:9200/_security/user/_has_privileges?pretty\" -H 'Content-Type: application/json' -d'\n{\n  \"cluster\": [ \"cluster:monitor/main\" ],\n  \"index\" : [\n    {\n      \"names\": [ \"logs-apm.app-default\", \"metrics-apm.app.*-default\", \"logs-apm.error-default\", \"metrics-apm.internal-default\", \"metrics-apm.profiling-default\", \"traces-apm.rum-default\", \"traces-apm-default\" ],\n      \"privileges\": [ \"auto_configure\",\"create_doc\" ]\n    },\n    {\n      \"names\": [ \"traces-apm.sampled-default\" ],\n      \"privileges\": [ \"auto_configure\",\"create_doc\",\"maintenance\",\"monitor\",\"read\" ]\n    }\n  ]\n}\n'\n```\n\n## 後記\n\n因為azure file使用`Transaction optimized`等級的價格每GB花費是1.763台幣，價格並不便宜所以只能將hot data存放在該區域中，\n在未來會放上elastic使用cluster的方式將hot data與warm data（使用hot等級）區分開來，減少帳單的開支\n\n## 參考連結\n\n[Service Accounts (Official document)](https://www.elastic.co/guide/en/elasticsearch/reference/current/service-accounts.html)\n\n[Create service account token api (official document)](https://www.elastic.co/guide/en/elasticsearch/reference/current/security-api-create-service-token.html)\n\n[azure file iops](https://docs.microsoft.com/en-us/azure/storage/files/storage-files-scale-targets)\n"},{"id":1650412800,"fileName":"azure-self-install","url":"2022/04/20/azure-self-install","title":"Azure 的自動裝機","description":"在之前已經有寫過AWS的裝機處理，這次改用Azure同樣的可以讓系統從scale out到上線不需要人工的處理就可以完成系統的部署與設定","date":"2022-04-20T00:00:00.000Z","tags":["devops","azure","prevision"],"published":true,"content":"\n在之前已經有寫過AWS的裝機處理，這次改用Azure同樣的可以讓系統從scale out到上線不需要人工的處理就可以完成系統的部署與設定\n\n## Azure 的VM Scale Set\n\n在AWS是稱為Auto Scaling Group，在Azure中的名稱是Virtual Machine Scale Set(以下簡稱VMSS)，這也是一個群組設定虛擬機器的規格, 伸縮的條件, 健康檢查等等的設定\n\ncustom_data的資料就是我們準備要設定開機後要執行的腳本，這個設定了以後在azure 的Portal是無法再看到的，所以如果不是使用IaC的話一定要找個地方做紀錄\nAzure的VMSS就有內建的檢查機制(extension區塊)，可以檢查VM的服務是否正確地被啟動，若沒有在時間內被測試成功的話機器會重新收回部署\n\n在terraform 有另一個設定 extension的module， `azurerm_virtual_machine_extension`設定如果要設定`healthRepairExtension`在我測試時是會失敗的，所以一定要在extension區塊中設定。\n\n```config\nresource \"azurerm_linux_virtual_machine_scale_set\" \"sample\" {\n  name                = \"${var.prefix}-vmss\"\n  resource_group_name = data.azurerm_resource_group.main.name\n  location            = data.azurerm_resource_group.main.location\n  zone_balance        = true\n  zones               = [1, 2, 3]\n  sku                 = var.machineSize\n  instances           = var.capacity.minimum\n  admin_username      = \"azureuser\"\n  custom_data         = filebase64(\"${path.module}/custom-data.sh\")\n\n  admin_ssh_key {\n    username   = \"azureuser\"\n    public_key = data.azurerm_ssh_public_key.logstash.public_key\n  }\n\n  automatic_instance_repair {\n    enabled      = true\n    grace_period = \"PT10M\"\n  }\n\n  source_image_reference {\n    publisher = \"canonical\"\n    offer     = \"0001-com-ubuntu-server-focal\"\n    sku       = \"20_04-lts-gen2\"\n    version   = \"latest\"\n  }\n\n  os_disk {\n    storage_account_type = \"Standard_LRS\"\n    caching              = \"ReadWrite\"\n    disk_size_gb         = 30\n  }\n\n  extension {\n    name                      = \"healthRepairExtension\"\n    publisher                 = \"Microsoft.ManagedServices\"\n    type                      = \"ApplicationHealthLinux\"\n    type_handler_version      = \"1.0\"\n    automatic_upgrade_enabled = true\n    settings                  = <<settings\n      {\n        \"protocol\" : \"http\",\n        \"port\" : 80,\n        \"requestPath\" : \"/\"\n      }\n    settings\n  }\n\n  network_interface {\n    name    = \"${var.prefix}-NIC\"\n    primary = true\n\n    ip_configuration {\n      name      = \"internal\"\n      primary   = true\n      subnet_id = azurerm_subnet.subnet.id\n    }\n  }\n\n  tags = {\n    env      = var.environment\n    service  = \"logstash\"\n    createby = \"brunojan\"\n    docker   = \"yes\"\n    date     = formatdate(\"YYYY/MM/DD hh:mm:ss\", timestamp())\n    version  = var.ap_version\n  }\n}\n```\n## VMSS的擴展計畫\n\n在Azure的設定呢，說真的我還沒有非常的理解整個設定，但目前看起來的設定較為麻煩...\n\n在Profile中，一定要有一組預設的設定資料，接下來才能在設定其他的擴展策略，所以我直接hard code一組default的設定，這個設定會是主要的擴展策略。\n其他的設定基本上可以依照特定的時間，或是情境來做設定\n\n在設定中的時間設定在Azure都是使用ISO-8601的設定標準來設定，這個部份對於我來說真的很不順手，也不容易理解...\n\n```config\nresource \"azurerm_monitor_autoscale_setting\" \"autoscale\" {\n  name                = \"${var.prefix}-scale-set\"\n  resource_group_name = data.azurerm_resource_group.main.name\n  location            = data.azurerm_resource_group.main.location\n  target_resource_id  = azurerm_linux_virtual_machine_scale_set.sample.id\n\n  profile {\n    name = \"default\"\n\n    capacity {\n      default = var.capacity.minimum\n      minimum = var.capacity.minimum\n      maximum = var.capacity.maximum\n    }\n\n    dynamic \"rule\" {\n      for_each = length(var.policies) > 0 ? var.policies : []\n      content {\n        metric_trigger {\n          metric_name        = rule.value.metric\n          metric_resource_id = azurerm_linux_virtual_machine_scale_set.sample.id\n          time_grain         = rule.value.grain\n          statistic          = rule.value.statistic\n          time_window        = rule.value.duration\n          time_aggregation   = rule.value.statistic\n          operator           = rule.value.operation\n          threshold          = rule.value.threshold\n          metric_namespace   = \"microsoft.compute/virtualmachinescalesets\"\n        }\n\n        scale_action {\n          direction = rule.value.action\n          type      = \"ChangeCount\"\n          value     = rule.value.count\n          cooldown  = rule.value.cooldown\n        }\n      }\n    }\n  }\n\n  dynamic \"profile\" {\n    for_each = length(var.schedules) > 0 ? var.schedules : []\n\n    content {\n      name = profile.value.name\n\n      capacity {\n        default = profile.value.minimum\n        minimum = profile.value.minimum\n        maximum = profile.value.maximum\n      }\n\n      recurrence {\n        timezone = \"Taipei Standard Time\"\n        days     = profile.value.days\n        hours    = profile.value.hours\n        minutes  = profile.value.minutes\n      }\n\n    }\n  }\n```\n\n## Terraform azurerm_virtual_machine_scale_set\n\n這個在未來的版本中已經被棄用了，所以如果有要使用terraform的記得改用`azurerm_linux_virtual_machine_scale_set`(Linux)與azurerm_windows_virtual_machine_scale_set(Windows)\n設定上基本差不多\n\n## 參考資料\n\n[ISO-8601 wiki](https://en.wikipedia.org/wiki/ISO_8601)\n\n[Terraform azurerm_virtual_machine_scale_set](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/virtual_machine_scale_set)\n"},{"id":1641168000,"fileName":"vulnerability-scanning-for-ssl-support-algorithm","url":"2022/01/03/vulnerability-scanning-for-ssl-support-algorithm","title":"弱點掃描-SSL加密演算法不安全的演算法","description":"最近公司資安檢查報告中被檢查出了一個關於SSL的加密連線的弱點，這個弱點是因為我們沒有把不安全的加密演算法關閉導致這個弱點的產生， 在公司的政策中線上的伺服器不能任意安裝任何程式，所以`IISCrypto`就只能放棄無法使用，所以我修改的部分是使用修改幾碼的方式進行， 由於我不太熟悉資安，修改後要如何驗證呢這些已知有問題的演算法是否已經正確的被關閉了呢？","date":"2022-01-03T00:00:00.000Z","tags":["vulnerability","ssl"],"published":true,"content":"\n最近公司資安檢查報告中被檢查出了一個關於SSL的加密連線的弱點，這個弱點是因為我們沒有把不安全的加密演算法關閉導致這個弱點的產生，\n在公司的政策中線上的伺服器不能任意安裝任何程式，所以`IISCrypto`就只能放棄無法使用，所以我修改的部分是使用修改幾碼的方式進行，\n由於我不太熟悉資安，修改後要如何驗證呢這些已知有問題的演算法是否已經正確的被關閉了呢？\n\n所以我又在網路上google找到幾個腳本，透過openssl與curl的搭配可以掃描我們的server支援了哪些SSL的加密方式，有從server site的檢查與client site的檢查。\n\n```sh\n# server side\nURL=\"https://yi-shiuan.github.io/\"\n\nciphers=$(openssl ciphers 'ALL:eNULL' | sed -e 's/:/ /g')\n\n for cipher in ${ciphers[@]}\n do\n echo -n Testing $cipher...\n result=$(echo -n | openssl s_client -cipher \"$cipher\" -connect $URL 2>&1)\n if [[ \"$result\" =~ \":error:\" ]] ; then\n   error=$(echo -n $result | cut -d':' -f6)\n   echo NO \\($error\\)\n else\n   if [[ \"$result\" =~ \"Cipher is ${cipher}\" || \"$result\" =~ \"Cipher    :\" ]] ; then\n     echo YES\n   else\n     echo UNKNOWN RESPONSE\n     echo $result\n   fi\n fi\n sleep 1\n done\n```\n\n```sh\n# client site的檢查\nURL=\"https://yi-shiuan.github.io/\"\n\nDELAY=1\nciphers=$(openssl ciphers 'ALL:eNULL' | sed -e 's/:/ /g')\n\nfor cipher in ${ciphers[@]}\ndo\n    printf -v pad %30s\n    printf \"Checking ${cipher:0:30} ... \"\n    curl -s -S -o /dev/null --no-progress-meter --tls-max 1.2 --ciphers $cipher $URL\n    if [ $? -eq 0 ]; then\n        echo OK\n    fi\ndone\n```\n\n### 參考資料\n\n[IISCrypto](https://www.nartac.com/Products/IISCrypto)\n\n[叡揚資訊](https://www.gss.com.tw/blog/set-https-connect-protocols-and-ciphers)\n\n[SSL Ciphers](https://curl.se/docs/ssl-ciphers.html)\n"},{"id":1639958400,"fileName":"dotnetconf-2021@study4","url":"2021/12/20/dotnetconf-2021@study4","title":"從黑暗時代到現代化的雲端部署與維運","description":"dotnetconf 2021 ＠ study4 從黑暗時代到現代化的雲端部署與維運","tags":["azure","vmss","cd","devops","prevision","study4","dotnetconf"],"date":"2021-12-20T00:00:00.000Z","published":true,"content":"\ndotnetconf 2021 ＠ study4 從黑暗時代到現代化的雲端部署與維運\n\n[投影片下載](https://cdn.adhome.com.tw/blogger/dotnetconf2021@STUDY4.pdf)\n\n## IAC 說明\n\n[IaC Repo](https://github.com/Yi-Shiuan/dotnet-conf-iac)\n\n### website 資料夾\n\nwebsite資料夾是建立各個環境的資源檔案，內容記載該服務需要產生哪些的資源項目以及各個環境上的配置，裡面的部分採用terraform撰寫\n\n- `main.tf` => 用來設定資院建立的內容與設定\n- `variable.tf` => 定義整個腳本中有哪些變數\n- `vars 資料夾` => 每一個環境上的設定值\n\n### initial-script\n\n自動安裝腳本，這裡面的`main.sh`是整個警本的進入點，每一個服務都會有一個資料夾，資料夾內會有一個`install.sh`的檔案，這是實際上application真正執行部署的腳本\n由main.sh去下載install.sh，並且執行install.sh\n\n\n"}],"allTags":{"gatsby.js":1,"next.js":2,"postgresql":1,"database":2,"dotnet":1,"aws":4,"devops":7,"prevision":6,"iot":2,"platformio":2,"arduino":2,"esp":1,"elk":3,"azure":4,"vulnerability":1,"ssl":2,"vmss":1,"cd":3,"study4":1,"dotnetconf":1,"selenium":2,"tdd":1,"react":3,"jest":1,"frontend":1,"layout":1,"ec2":1,"iac":1,"terraform":1,"ci":1,"jenkins":1,"ecs":1,"ansible":1,"redis":2,"protobuf":2,"serialize":2,"deserialize":2,"pub":1,"sub":1,"notify":1},"total":25},"__N_SSG":true}