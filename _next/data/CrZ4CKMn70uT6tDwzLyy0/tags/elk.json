{"pageProps":{"posts":[{"id":1653004800,"fileName":"self-hosted-elasticsearch-8.2","url":"2022/05/20/self-hosted-elasticsearch-8.2","title":"自建Elasticsearch 8.2","description":"這週在處理自建的elasticsearch相關的狀況，今天處理告一段落後來個小筆記未來遇到才不會又搞了老半天...","date":"2022-05-20T00:00:00.000Z","tags":["elk","prevision"],"published":true,"content":"\n這週在處理在azure自建的elasticsearch相關的狀況，今天處理告一段落後來個小筆記未來遇到才不會又搞了老半天...\n\n為什麼要自建elastic呢？主要因為之前使用azure marketplace建立的elastic cloud的saas服務，現在需要把維運的職責交給SRE團隊，\n在移交的過程中發現了azure marketplace所建立的saas服務竟然不能移轉owner！只能將該服務的權限做共享而且必須將訂閱升級到Golden的等級，\n代表每個月的azure帳單又要多最少百元美金的支出...未來帳號如果被停用或是變更，有可能elastic cloud上的資料會有所影響，迫於無奈下只好走向自建的路了\n\n在自建時需要選好許多azure的服務相關的infra設計這些工作可少不了...最後決定了這些infra與azure的服務\n\n#### 1. elasticsearch server + kibana server\n\n使用vmss的服務建立虛擬機器，虛擬機器的規格是使用E2s v5的規格，根據過往經驗elasticsearch伺服器在尖峰的狀態下會使用較多的記憶體，而對於cpu要求較少一些\n對於網路的頻寬要求與對於硬碟的iops都有較大的要求，所以選用了esv5等級的機器\n\n#### 2. logstash server\n\nlogstash 服務也是採用vmss來建立虛擬機器，比較不一樣的是logstash對於cpu的要求較多，他需要去解析log還要針對log做相對應的處理，所以我們選用的是B1s的規格\n然後針對他cpu與memory的使用率做scale out/in的處理\n\n在主機中我使用的是container而非直接安裝相關的服務，然後搭配過去preversion的手法來建立伺服器。\n\n#### 3. Storage\n\n存放資料的磁區選用，這個在規劃時的poc最為困擾...在azure直接使用virtual machine的服務可以掛載managed disk的磁區，但使用vmss產生的vm是無法使用managed disk的！\n但...vmss或是vm建立的硬碟會隨這vm刪除或關閉而消失，所以我們必須得用另外一組的硬碟...後來找到了另外一種解決方案，azure file的服務，\n這樣一來就可以透過SMB掛載一個永久的硬碟，未來的log就能完整地被保留下來不會因為vm被刪除而消彌。\n\n> ps. azure file目前還不知道這樣的使用情境可以支撐多少的iops寫入與讀取，有待未來實驗\n> 根據官方文件指出每秒的iops是20,000 IOPS的讀取的速度基本上可以跟SSD差不多\n\n### 內建帳號使用 Service account token\n\n在使用8.0過後的版本kibana的服務官方預設不使用帳號密碼的方式登入，需要使用service account token的方式登入連線，然後按照官方的指引點入的連結會請你呼叫建立token的api\n```sh\n# create service account token\ncurl -X POST -u elastic:changeme \"localhost:9200/_security/service/elastic/fleet-server/credential/token?pretty\"\n```\nresponse\n```json\n{\n  \"created\": true,\n  \"token\": {\n    \"name\": \"token1\",\n    \"value\": \"AAEAAWVsYXN0aWM...vZmxlZXQtc2VydmVyL3Rva2VuMTo3TFdaSDZ\"\n  }\n}\n```\n然後在kibana上使用service account token登入，但只使用這樣的方式建立的token放在kibana上使用是可以登入elasticsearch，\n但在操作indices的時候就會出現錯誤`security_exception`說你沒有權限取得indices的資料\n```yaml\n# kibana.yml config\nserver.name: kibana\nserver.host: 0.0.0.0\nelasticsearch.hosts: [ \"http://{{elasticsearch}}:{{port}}\" ]\nxpack.monitoring.ui.container.elasticsearch.enabled: true\n\nelasticsearch.serviceAccountToken: AAEAAWVs......EtHd1E\n```\n好的，後來發現其實api呼叫的參數不對，官方在錯誤輸出的console上給的網址是會呼叫fleet-server的服務，而不是給kibana使用的所以我們要把fleet-server的token\n改成kibana服務的token，這樣就可以登入並且取得indices的資料順利的啟動kibana了\n```shell\n# for create kibana service account\ncurl -X POST -u elastic:changeme \"localhost:9200/_security/service/elastic/kibana/credential/token?pretty\"\n```\n```shell\n# check permission\ncurl -H \"Authorization: Bearer AAE.......1E\" -X GET \"localhost:9200/_security/user/_has_privileges?pretty\" -H 'Content-Type: application/json' -d'\n{\n  \"cluster\": [ \"cluster:monitor/main\" ],\n  \"index\" : [\n    {\n      \"names\": [ \"logs-apm.app-default\", \"metrics-apm.app.*-default\", \"logs-apm.error-default\", \"metrics-apm.internal-default\", \"metrics-apm.profiling-default\", \"traces-apm.rum-default\", \"traces-apm-default\" ],\n      \"privileges\": [ \"auto_configure\",\"create_doc\" ]\n    },\n    {\n      \"names\": [ \"traces-apm.sampled-default\" ],\n      \"privileges\": [ \"auto_configure\",\"create_doc\",\"maintenance\",\"monitor\",\"read\" ]\n    }\n  ]\n}\n'\n```\n\n## 後記\n\n因為azure file使用`Transaction optimized`等級的價格每GB花費是1.763台幣，價格並不便宜所以只能將hot data存放在該區域中，\n在未來會放上elastic使用cluster的方式將hot data與warm data（使用hot等級）區分開來，減少帳單的開支\n\n## 參考連結\n\n[Service Accounts (Official document)](https://www.elastic.co/guide/en/elasticsearch/reference/current/service-accounts.html)\n\n[Create service account token api (official document)](https://www.elastic.co/guide/en/elasticsearch/reference/current/security-api-create-service-token.html)\n\n[azure file iops](https://docs.microsoft.com/en-us/azure/storage/files/storage-files-scale-targets)\n"},{"id":1635552000,"fileName":"logstash-azure-event-hub-input","url":"2021/10/30/logstash-azure-event-hub-input","title":"Logstash Azure event hub input 設定","description":"最近又在規劃ELK的設定，這次比較不一樣的地方我選擇了elastic cloud以及服務部署的方式都採用PaaS的方式作為部署， 加掛volume或是在機器上安裝filebeat都是一個比較困難的事情，所以一開始考慮使用azure blob queue的方式存放log， 但後來選擇了官方有提供的input套件，Azure Event Hub來寫log在使用logstash去讀取傳送到elasticsearch上","date":"2021-10-30T00:00:00.000Z","tags":["azure","elk"],"published":true,"content":"\n最近又在規劃ELK的設定，這次比較不一樣的地方我選擇了elastic cloud以及服務部署的方式都採用PaaS的方式作為部署，\n加掛volume或是在機器上安裝filebeat都是一個比較困難的事情，所以一開始考慮使用azure blob queue的方式存放log，\n但後來選擇了官方有提供的input套件，Azure Event Hub來寫log在使用logstash去讀取傳送到elasticsearch上\n\n根據官網的文件操作後會一直出現\n`The configuration will result in overwriting offsets. Please ensure that the each Event Hub's consumer_group is using a unique storage container.`\n這樣的錯誤訊息，也採用了進階的設定去使用，但因為只有一組採用進階的方式設定有點太過複雜所以又改回原本設定，後來想我的event hub的connection string有兩組會不會因為這樣我需要多個storage container的存放空間，\n後來將其中一組刪除後即可正常運作\n\n```config\n# 會出錯的logstash pipeline config\ninput {\n    azure_event_hubs {\n        event_hub_connections => [\"Endpoint=sb://<<event hub>>.servicebus.windows.net/;SharedAccessKeyName=logsta...\",\n            \"Endpoint=sb://<<event hub>>.servicebus.windows.net/;SharedAccessKeyName=logsta...\"]\n        storage_connection => \"DefaultEndpointsProtocol=https;...\"\n        consumer_group => \"logstash\"\n        decorate_events => true\n        threads => 8\n    }\n}\nfilter {\n    json {\n        source => \"message\"\n    }\n    date {\n        match => [ \"Timestamp\", \"ISO8601\" ]\n        target => \"@timestamp\"\n    }\n    mutate {\n        rename => [\"MessageTemplate\", \"message\" ]\n        rename => [\"Level\", \"level\" ]\n        merge => { \"message\" => \"Exception\" }\n        remove_field => [\"Exception\", \"Timestamp\"]\n    }\n}\noutput {\n    elasticsearch {\n        cloud_id => \"<<Cloud id>>\"\n        cloud_auth => \"<<user>>:<<password>>\"\n        index => \"demo-%{+YYYY.w}\"\n    }\n}\n```\n\n```config\n# 最後的 logstash pipeline config\ninput {\n    azure_event_hubs {\n        event_hub_connections => [\"Endpoint=sb://<<event hub>>.servicebus.windows.net/;SharedAccessKeyName=logsta...\"]\n        storage_connection => \"DefaultEndpointsProtocol=https;...\"\n        consumer_group => \"logstash\"\n        decorate_events => true\n        threads => 8\n    }\n}\nfilter {\n    json {\n        source => \"message\"\n    }\n    date {\n        match => [ \"Timestamp\", \"ISO8601\" ]\n        target => \"@timestamp\"\n    }\n    mutate {\n        rename => [\"MessageTemplate\", \"message\" ]\n        rename => [\"Level\", \"level\" ]\n        merge => { \"message\" => \"Exception\" }\n        remove_field => [\"Exception\", \"Timestamp\"]\n    }\n}\noutput {\n    elasticsearch {\n        cloud_id => \"<<Cloud id>>\"\n        cloud_auth => \"<<user>>:<<password>>\"\n        index => \"demo-%{+YYYY.w}\"\n    }\n}\n```\n\n\n### 參考資料\n[Github - logstash-input-azure_event_hubs](https://github.com/logstash-plugins/logstash-input-azure_event_hubs)\n"},{"id":1610064000,"fileName":"elasticsearch-tuning-and-auto-operation","url":"2021/01/08/elasticsearch-tuning-and-auto-operation","title":"Elasticsearch 效能調整與自動維運","description":"在Index Management中有個index templates的頁簽，在這裡可以改變一些index的行為或是屬性， 有些index屬性對於整個ELK的查詢或是機器的影響是很巨大的，當Log量越大的時候就需要改變一些設定， 尤其是放在雲端的ELK，如果使用越大的機器消費金額就會變得很可觀，在不是賺錢的機器上還是能省則省。","date":"2021-01-08T00:00:00.000Z","tags":["elk","devops"],"published":true,"content":"\n## 針對index的一些效能調校\n\n在Index Management中有個index templates的頁簽，在這裡可以改變一些index的行為或是屬性，\n有些index屬性對於整個ELK的查詢或是機器的影響是很巨大的，當Log量越大的時候就需要改變一些設定，\n尤其是放在雲端的ELK，如果使用越大的機器消費金額就會變得很可觀，在不是賺錢的機器上還是能省則省。\n\n`index.codec`在官方的文件中有兩個選項，預設是Default採用LZ4的壓縮，另一個選項是*best_compression*，\n使用它可以得到更高的壓縮效率但會增加CPU的附載，不過減少硬碟的空間是可觀的\n\n`refresh_interval`這個在官方文件說明是index的刷新頻率，這個選項會影響到新增的log多久內可能不會被看見，\n但refresh index他需要消耗許多的CPU來處理，這個值如果越大刷新的頻率就會降低，機器的CPU usage就不會被這個吃掉，\n可以減少一些CPU的運算\n\n`number_of_replicas`是Elasticsearch會建立多少個副本，但複本越多所需要消耗的CPU與硬碟空間就會加大\n\n```json\n{\n  \"index\": {\n    \"lifecycle\": {\n      \"name\": \"production\"\n    },\n    \"codec\": \"best_compression\",\n    \"refresh_interval\": \"15s\",\n    \"number_of_replicas\": 0\n  }\n}\n```\n\n## 自動維運Index的小技巧\n\n通常架設了ELK初期會常常觀看一些硬碟空間, CPU usage, Memory usage等等的，時間久了就會忘記了...\n\n但是硬碟的空間是有限的，Application Log其實也是有時效性的，他不需要永久的存在在硬碟上(畢竟要花錢的...)所以自動刪除index就變得很重要，\n在Index Lifecycle Policies中我會設定兩個policy，一個production跟一個non-production的，production通常會留存30天以，\n而非production的一般來說在兩週到三週就沒有參考價值了，所以非production只留存14天。\n\n![ELK index lifecycle](elasticsearch-tuning-and-auto-operation/index-lifecycle.png)\n\n## 參考連結\n[Elasticsearch Index Module](https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html)\n\n[Tune for indexing speed](https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html)\n"}],"allTags":{"vue":1,"nuxt":1,"vite":1,"devops":8,"study4":2,"dotnetconf":2,"aws":5,"frontend":2,"next.js":4,"react":5,"i18n":1,"gatsby.js":1,"postgresql":1,"database":2,"dotnet":1,"prevision":6,"iot":2,"platformio":2,"arduino":2,"esp":1,"elk":3,"azure":4,"vulnerability":1,"ssl":2,"vmss":1,"cd":3,"selenium":2,"tdd":1,"jest":1,"layout":1,"ec2":1,"iac":1,"terraform":1,"ci":1,"jenkins":1,"ecs":1,"ansible":1,"redis":2,"protobuf":2,"serialize":2,"deserialize":2,"pub":1,"sub":1,"notify":1}},"__N_SSG":true}