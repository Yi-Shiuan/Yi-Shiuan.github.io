{"pageProps":{"id":1635552000,"fileName":"logstash-azure-event-hub-input","url":"2021/10/30/logstash-azure-event-hub-input","title":"Logstash Azure event hub input 設定","description":"最近又在規劃ELK的設定，這次比較不一樣的地方我選擇了elastic cloud以及服務部署的方式都採用PaaS的方式作為部署， 加掛volume或是在機器上安裝filebeat都是一個比較困難的事情，所以一開始考慮使用azure blob queue的方式存放log， 但後來選擇了官方有提供的input套件，Azure Event Hub來寫log在使用logstash去讀取傳送到elasticsearch上","date":"2021-10-30T00:00:00.000Z","tags":["azure","elk"],"published":true,"content":"\n最近又在規劃ELK的設定，這次比較不一樣的地方我選擇了elastic cloud以及服務部署的方式都採用PaaS的方式作為部署，\n加掛volume或是在機器上安裝filebeat都是一個比較困難的事情，所以一開始考慮使用azure blob queue的方式存放log，\n但後來選擇了官方有提供的input套件，Azure Event Hub來寫log在使用logstash去讀取傳送到elasticsearch上\n\n根據官網的文件操作後會一直出現\n`The configuration will result in overwriting offsets. Please ensure that the each Event Hub's consumer_group is using a unique storage container.`\n這樣的錯誤訊息，也採用了進階的設定去使用，但因為只有一組採用進階的方式設定有點太過複雜所以又改回原本設定，後來想我的event hub的connection string有兩組會不會因為這樣我需要多個storage container的存放空間，\n後來將其中一組刪除後即可正常運作\n\n```config\n# 會出錯的logstash pipeline config\ninput {\n    azure_event_hubs {\n        event_hub_connections => [\"Endpoint=sb://<<event hub>>.servicebus.windows.net/;SharedAccessKeyName=logsta...\",\n            \"Endpoint=sb://<<event hub>>.servicebus.windows.net/;SharedAccessKeyName=logsta...\"]\n        storage_connection => \"DefaultEndpointsProtocol=https;...\"\n        consumer_group => \"logstash\"\n        decorate_events => true\n        threads => 8\n    }\n}\nfilter {\n    json {\n        source => \"message\"\n    }\n    date {\n        match => [ \"Timestamp\", \"ISO8601\" ]\n        target => \"@timestamp\"\n    }\n    mutate {\n        rename => [\"MessageTemplate\", \"message\" ]\n        rename => [\"Level\", \"level\" ]\n        merge => { \"message\" => \"Exception\" }\n        remove_field => [\"Exception\", \"Timestamp\"]\n    }\n}\noutput {\n    elasticsearch {\n        cloud_id => \"<<Cloud id>>\"\n        cloud_auth => \"<<user>>:<<password>>\"\n        index => \"demo-%{+YYYY.w}\"\n    }\n}\n```\n\n```config\n# 最後的 logstash pipeline config\ninput {\n    azure_event_hubs {\n        event_hub_connections => [\"Endpoint=sb://<<event hub>>.servicebus.windows.net/;SharedAccessKeyName=logsta...\"]\n        storage_connection => \"DefaultEndpointsProtocol=https;...\"\n        consumer_group => \"logstash\"\n        decorate_events => true\n        threads => 8\n    }\n}\nfilter {\n    json {\n        source => \"message\"\n    }\n    date {\n        match => [ \"Timestamp\", \"ISO8601\" ]\n        target => \"@timestamp\"\n    }\n    mutate {\n        rename => [\"MessageTemplate\", \"message\" ]\n        rename => [\"Level\", \"level\" ]\n        merge => { \"message\" => \"Exception\" }\n        remove_field => [\"Exception\", \"Timestamp\"]\n    }\n}\noutput {\n    elasticsearch {\n        cloud_id => \"<<Cloud id>>\"\n        cloud_auth => \"<<user>>:<<password>>\"\n        index => \"demo-%{+YYYY.w}\"\n    }\n}\n```\n\n\n### 參考資料\n[Github - logstash-input-azure_event_hubs](https://github.com/logstash-plugins/logstash-input-azure_event_hubs)\n","allTags":{"vue":1,"nuxt":1,"vite":1,"aws":5,"frontend":2,"next.js":4,"react":5,"i18n":1,"gatsby.js":1,"postgresql":1,"database":2,"dotnet":1,"devops":8,"prevision":6,"iot":2,"platformio":2,"arduino":2,"esp":1,"elk":3,"azure":4,"vulnerability":1,"ssl":2,"vmss":1,"cd":3,"study4":2,"dotnetconf":2,"selenium":2,"tdd":1,"jest":1,"layout":1,"ec2":1,"iac":1,"terraform":1,"ci":1,"jenkins":1,"ecs":1,"ansible":1,"redis":2,"protobuf":2,"serialize":2,"deserialize":2,"pub":1,"sub":1,"notify":1}},"__N_SSG":true}